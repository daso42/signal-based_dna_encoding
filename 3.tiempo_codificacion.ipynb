{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gc\n",
    "from itertools import product\n",
    "import pywt\n",
    "from scipy.fft import fft\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def fourier(sequences, is_str=True):\n",
    "    \"\"\"Applies Fourier transform to sequences.\"\"\"\n",
    "    if is_str:\n",
    "        templist = []\n",
    "        for seq in sequences:\n",
    "            num_seq = [ord(char) for char in seq]\n",
    "            fft_seq = fft(num_seq)\n",
    "            fft_seq = np.abs(fft_seq)\n",
    "            templist.append(fft_seq[1:len(fft_seq)//2])\n",
    "        return templist\n",
    "    else:\n",
    "        templist = []\n",
    "        for seq in sequences:\n",
    "            fft_seq = fft(seq)\n",
    "            fft_seq = np.abs(fft_seq)\n",
    "            templist.append(fft_seq[1:len(fft_seq)//2])\n",
    "        return templist\n",
    "\n",
    "def generate_kmers_dict(k, unique_chars=set('ACGNT')):\n",
    "    \"\"\"Generates k-mers dictionary.\"\"\"\n",
    "    kmers = product(unique_chars, repeat=k)\n",
    "    return {''.join(kmer): i for i, kmer in enumerate(kmers)}\n",
    "\n",
    "def k_mers(sequencias, k=3, unique_chars=set('ACGNT')):\n",
    "    \"\"\"K-mers encoding.\"\"\"\n",
    "    kmers_map = generate_kmers_dict(k, unique_chars)\n",
    "    templist = []\n",
    "    for seq in sequencias:\n",
    "        temp = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "        templist.append([kmers_map[i] for i in temp])\n",
    "    return templist\n",
    "\n",
    "def one_hot(sequences, max_len, unique_chars=set('ACGNT'), reshape=True):\n",
    "    \"\"\"One-hot encoding.\"\"\"\n",
    "    mapping = {j: i for i, j in enumerate(unique_chars)}\n",
    "    sequencias_procesadas = []\n",
    "    if reshape == True:\n",
    "        for s in sequences:\n",
    "            temp = np.zeros((max_len, len(unique_chars)))\n",
    "            for c in zip(s, temp):\n",
    "                c[1][mapping[c[0]]] = 1\n",
    "            sequencias_procesadas.append(temp.reshape(-1))\n",
    "        return sequencias_procesadas\n",
    "    elif reshape == False:\n",
    "        for s in sequences:\n",
    "            temp = np.zeros((max_len, len(unique_chars)))\n",
    "            for c in zip(s, temp):\n",
    "                c[1][mapping[c[0]]] = 1\n",
    "            sequencias_procesadas.append(temp)\n",
    "        return sequencias_procesadas\n",
    "\n",
    "def wavelet(sequences, numeric=False, wavelet='db1', level=5):\n",
    "    \"\"\"Wavelet transform.\"\"\"\n",
    "    templist = []\n",
    "    if numeric == False:\n",
    "        for seq in sequences:\n",
    "            num_seq = [ord(char) for char in seq]\n",
    "            coeffs = pywt.wavedec(num_seq, wavelet, level)\n",
    "            templist.append(np.concatenate(coeffs))\n",
    "        return templist\n",
    "    elif numeric == True:\n",
    "        for seq in sequences:\n",
    "            coeffs = pywt.wavedec(seq, wavelet, level)\n",
    "            templist.append(np.concatenate(coeffs))\n",
    "        return templist\n",
    "\n",
    "def pad_sequences(sequences, maxlen):\n",
    "    \"\"\"Pads sequences to equal length.\"\"\"\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < maxlen:\n",
    "            seq += 'N' * (maxlen - len(seq))\n",
    "        else:\n",
    "            seq = seq[:maxlen]\n",
    "        padded_sequences.append(seq)\n",
    "    return padded_sequences\n",
    "\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    \"\"\"Measures execution time.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "def measure_memory(result):\n",
    "    \"\"\"Measures memory usage of result.\"\"\"\n",
    "    if isinstance(result, list):\n",
    "        tamano_lista = sys.getsizeof(result)\n",
    "        if all(isinstance(item, np.ndarray) for item in result):\n",
    "            tamano_elementos = sum(arr.nbytes for arr in result)\n",
    "        else:\n",
    "            tamano_elementos = sum(sys.getsizeof(elemento) for elemento in result)\n",
    "            for elemento in result:\n",
    "                if isinstance(elemento, (list, np.ndarray)):\n",
    "                    if isinstance(elemento, list):\n",
    "                        tamano_elementos += sum(sys.getsizeof(subelem) for subelem in elemento)\n",
    "                    elif isinstance(elemento, np.ndarray):\n",
    "                        tamano_elementos += elemento.nbytes - sys.getsizeof(elemento)\n",
    "        \n",
    "        tamano_total = tamano_lista + tamano_elementos\n",
    "        return tamano_total / (1024 * 1024)  # MB\n",
    "    elif isinstance(result, np.ndarray):\n",
    "        return result.nbytes / (1024 * 1024)  # MB\n",
    "    else:\n",
    "        return sys.getsizeof(result) / (1024 * 1024)  # MB\n",
    "\n",
    "def benchmark_encoding(func, sequences, func_name, n_runs=5, **kwargs):\n",
    "    \"\"\"Executes benchmark for an encoding function.\"\"\"\n",
    "    print(f\"Benchmarking {func_name}...\")\n",
    "    \n",
    "    time_results = []\n",
    "    memory_results = []\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        gc.collect()\n",
    "        result, exec_time = measure_time(func, sequences, **kwargs)\n",
    "        memory_size = measure_memory(result)\n",
    "        \n",
    "        time_results.append(exec_time)\n",
    "        memory_results.append(memory_size)\n",
    "        gc.collect()\n",
    "    \n",
    "    return {\n",
    "        'encoding': func_name,\n",
    "        'avg_time': np.mean(time_results),\n",
    "        'std_time': np.std(time_results),\n",
    "        'avg_memory': np.mean(memory_results),\n",
    "        'std_memory': np.std(memory_results),\n",
    "        'all_times': time_results,\n",
    "        'all_memories': memory_results\n",
    "    }\n",
    "\n",
    "def run_combined_benchmarks(df, n_runs=5, multiplier=1):\n",
    "    \"\"\"Runs benchmarks for both AS and PS sequences.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Multiply sequences if needed\n",
    "    if multiplier > 1:\n",
    "        df_multiplied = pd.concat([df] * multiplier, ignore_index=True)\n",
    "        print(f\"Multiplied dataset by {multiplier}x: {len(df)} -> {len(df_multiplied)} sequences\")\n",
    "    else:\n",
    "        df_multiplied = df\n",
    "    \n",
    "    # AS sequences\n",
    "    print(f\"\\n=== BENCHMARKING AS SEQUENCES (N={len(df_multiplied)}) ===\")\n",
    "    as_sequences = df_multiplied['as'].values\n",
    "    as_max_len = len(as_sequences[0])\n",
    "    \n",
    "    # AS - One Hot\n",
    "    result = benchmark_encoding(one_hot, as_sequences, 'AS-One Hot', \n",
    "                              n_runs, max_len=as_max_len)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # AS - K-mers\n",
    "    result = benchmark_encoding(k_mers, as_sequences, 'AS-K-mers', n_runs)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # AS - FFT\n",
    "    result = benchmark_encoding(fourier, as_sequences, 'AS-FFT', n_runs)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # AS - Wavelet\n",
    "    result = benchmark_encoding(wavelet, as_sequences, 'AS-Wavelet', n_runs)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # AS combinations\n",
    "    as_kmers = k_mers(as_sequences)\n",
    "    as_onehot = one_hot(as_sequences, as_max_len)\n",
    "    \n",
    "    result = benchmark_encoding(fourier, as_kmers, 'AS-K-mers + FFT', \n",
    "                              n_runs, is_str=False)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    result = benchmark_encoding(fourier, as_onehot, 'AS-One Hot + FFT', \n",
    "                              n_runs, is_str=False)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    result = benchmark_encoding(wavelet, as_kmers, 'AS-K-mers + Wavelet', \n",
    "                              n_runs, numeric=True)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    result = benchmark_encoding(wavelet, as_onehot, 'AS-One Hot + Wavelet', \n",
    "                              n_runs, numeric=True)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(as_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # PS sequences\n",
    "    print(f\"\\n=== BENCHMARKING PS SEQUENCES (N={len(df_multiplied)}) ===\")\n",
    "    ps_sequences = df_multiplied['ps'].values\n",
    "    ps_max_len = len(ps_sequences[0])\n",
    "    \n",
    "    # PS - One Hot\n",
    "    result = benchmark_encoding(one_hot, ps_sequences, 'PS-One Hot', \n",
    "                              n_runs, max_len=ps_max_len)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # PS - K-mers\n",
    "    result = benchmark_encoding(k_mers, ps_sequences, 'PS-K-mers', n_runs)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # PS - FFT\n",
    "    result = benchmark_encoding(fourier, ps_sequences, 'PS-FFT', n_runs)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # PS - Wavelet\n",
    "    result = benchmark_encoding(wavelet, ps_sequences, 'PS-Wavelet', n_runs)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    # PS combinations\n",
    "    ps_kmers = k_mers(ps_sequences)\n",
    "    ps_onehot = one_hot(ps_sequences, ps_max_len)\n",
    "    \n",
    "    result = benchmark_encoding(fourier, ps_kmers, 'PS-K-mers + FFT', \n",
    "                              n_runs, is_str=False)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    result = benchmark_encoding(fourier, ps_onehot, 'PS-One Hot + FFT', \n",
    "                              n_runs, is_str=False)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    result = benchmark_encoding(wavelet, ps_kmers, 'PS-K-mers + Wavelet', \n",
    "                              n_runs, numeric=True)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    result = benchmark_encoding(wavelet, ps_onehot, 'PS-One Hot + Wavelet', \n",
    "                              n_runs, numeric=True)\n",
    "    result['multiplier'] = multiplier\n",
    "    result['n_sequences'] = len(ps_sequences)\n",
    "    results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def load_and_process_data():\n",
    "    \"\"\"Loads and processes the dataset.\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv('datos/datos_filtrados_sin_encoding.csv')\n",
    "    df = df[['genus', 'se', 'sequence', 'gc_content']]\n",
    "    df = df.rename(columns={'se': 'as'})\n",
    "    \n",
    "    print(\"Processing sequences...\")\n",
    "    # Sequence padding\n",
    "    maxlen = max([len(i) for i in df['sequence']])\n",
    "    df['ps'] = pad_sequences(df['sequence'], maxlen)\n",
    "    \n",
    "    # Add length information\n",
    "    df['len_sequence'] = [len(i) for i in df['sequence']]\n",
    "    df['len_ps'] = [len(i) for i in df['ps']]\n",
    "    df['len_as'] = [len(i) for i in df['as']]\n",
    "    \n",
    "    # Class mapping\n",
    "    map_genus = {j: i for i, j in enumerate(df['genus'].unique())}\n",
    "    df['clases_modelos'] = df['genus'].map(map_genus)\n",
    "    \n",
    "    print(f\"Dataset loaded: {len(df)} sequences\")\n",
    "    print(f\"Max original sequence length: {max(df['len_sequence'])}\")\n",
    "    print(f\"Padded sequence length: {df['len_ps'][0]}\")\n",
    "    print(f\"AS sequence length: {df['len_as'][0]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ensure_directory(path):\n",
    "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Created directory: {path}\")\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'results/encoding_time'\n",
    "ensure_directory(results_dir)\n",
    "\n",
    "# Load and process data\n",
    "df = load_and_process_data()\n",
    "\n",
    "# Run benchmarks for different multipliers\n",
    "multipliers = [1, 2, 3, 4, 5]\n",
    "all_results = []\n",
    "\n",
    "for mult in multipliers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RUNNING BENCHMARK WITH MULTIPLIER {mult}x\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = run_combined_benchmarks(df, n_runs=50, multiplier=mult)\n",
    "    all_results.append(results)\n",
    "\n",
    "# Combine all results\n",
    "combined_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Save all results in single file\n",
    "results_filepath = os.path.join(results_dir, 'benchmark_results.csv')\n",
    "combined_results.to_csv(results_filepath, index=False)\n",
    "print(f\"All results saved: {results_filepath}\")\n",
    "\n",
    "# Show summary for each multiplier\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BENCHMARK RESULTS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for mult in multipliers:\n",
    "    mult_results = combined_results[combined_results['multiplier'] == mult]\n",
    "    print(f\"\\nMultiplier {mult}x (N={mult_results['n_sequences'].iloc[0]} sequences):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    display_results = mult_results[['encoding', 'avg_time', 'std_time', 'avg_memory', 'std_memory']]\n",
    "    display_results = display_results.sort_values('avg_time')\n",
    "    print(display_results.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nFastest encoding: {display_results.iloc[0]['encoding']} ({display_results.iloc[0]['avg_time']:.3f}s)\")\n",
    "    print(f\"Most memory efficient: {display_results.nsmallest(1, 'avg_memory').iloc[0]['encoding']} ({display_results.nsmallest(1, 'avg_memory').iloc[0]['avg_memory']:.2f} MB)\")\n",
    "\n",
    "print(f\"\\nAll results saved in: {results_filepath}\")\n",
    "print(\"Benchmark completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
