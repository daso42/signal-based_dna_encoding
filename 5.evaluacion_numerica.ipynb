{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bbcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Librerías básicas\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librerías de machine learning\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Configuración\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Variables globales de configuración\n",
    "RANDOM_STATE = 42\n",
    "MEMORY_EFFICIENT = True\n",
    "MAX_MODELS_IN_MEMORY = 5\n",
    "\n",
    "# Variables globales de rutas de archivos\n",
    "models_base_dir = \"modelos\"\n",
    "results_base_dir = \"results\"\n",
    "evaluation_results_dir = \"results/evaluation_results\"\n",
    "logs_dir = \"logs\"\n",
    "evaluation_data_file = \"datos/evaluation_data.parquet\"\n",
    "\n",
    "# Nombres de archivos de salida\n",
    "csv_output_filename = \"evaluation_results.csv\"\n",
    "excel_output_filename = \"evaluation_complete.xlsx\"\n",
    "json_output_filename = \"evaluation_detailed.json\"\n",
    "\n",
    "# Extensiones de archivos\n",
    "model_file_extension = \".joblib\"\n",
    "metadata_file_suffix = \"_metadata.json\"\n",
    "\n",
    "# Crear directorios necesarios\n",
    "os.makedirs(evaluation_results_dir, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123aa082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage(obj):\n",
    "    \"\"\"Calcula el uso de memoria de un objeto en MB\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.nbytes / (1024 * 1024)\n",
    "    elif isinstance(obj, list):\n",
    "        total_size = sys.getsizeof(obj)\n",
    "        for item in obj:\n",
    "            if isinstance(item, np.ndarray):\n",
    "                total_size += item.nbytes\n",
    "            else:\n",
    "                total_size += sys.getsizeof(item)\n",
    "        return total_size / (1024 * 1024)\n",
    "    else:\n",
    "        return sys.getsizeof(obj) / (1024 * 1024)\n",
    "\n",
    "def discover_models(models_dir=None):\n",
    "    \"\"\"Descubre modelos desde estructura fija: modelos/[Algorithm]/[Encoding].joblib\"\"\"\n",
    "    if models_dir is None:\n",
    "        models_dir = models_base_dir\n",
    "        \n",
    "    print(f\"Cargando modelos desde '{models_dir}'\")\n",
    "    \n",
    "    if not os.path.exists(models_dir):\n",
    "        print(f\"El directorio {models_dir} no existe\")\n",
    "        return []\n",
    "    \n",
    "    discovered_models = []\n",
    "    \n",
    "    # Algoritmos esperados\n",
    "    algorithms = ['SVM', 'RandomForest', 'XGBoost']\n",
    "    \n",
    "    # Buscar en cada directorio de algoritmo\n",
    "    for algorithm in algorithms:\n",
    "        algorithm_dir = os.path.join(models_dir, algorithm)\n",
    "        \n",
    "        if not os.path.exists(algorithm_dir):\n",
    "            print(f\"Directorio {algorithm} no encontrado\")\n",
    "            continue\n",
    "        \n",
    "        # Buscar archivos .joblib en el directorio del algoritmo\n",
    "        for file in os.listdir(algorithm_dir):\n",
    "            if file.endswith(model_file_extension):\n",
    "                encoding = os.path.splitext(file)[0]\n",
    "                model_file = os.path.join(algorithm_dir, file)\n",
    "                \n",
    "                # Buscar archivo de metadata correspondiente\n",
    "                metadata_file = os.path.join(algorithm_dir, f\"{encoding}{metadata_file_suffix}\")\n",
    "                metadata = {}\n",
    "                \n",
    "                if os.path.exists(metadata_file):\n",
    "                    try:\n",
    "                        with open(metadata_file, 'r') as f:\n",
    "                            metadata = json.load(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error cargando metadata para {algorithm}/{file}: {e}\")\n",
    "                \n",
    "                model_info = {\n",
    "                    'algorithm': algorithm,\n",
    "                    'encoding': encoding,\n",
    "                    'model_file': model_file,\n",
    "                    'metadata_file': metadata_file if os.path.exists(metadata_file) else None,\n",
    "                    'metadata': metadata\n",
    "                }\n",
    "                \n",
    "                discovered_models.append(model_info)\n",
    "                print(f\"  Encontrado: {algorithm} - {encoding}\")\n",
    "    \n",
    "    print(f\"Total de modelos descubiertos: {len(discovered_models)}\")\n",
    "    return discovered_models\n",
    "\n",
    "def load_model_safely(model_path):\n",
    "    \"\"\"Carga un modelo de forma segura\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model = joblib.load(model_path)\n",
    "        load_time = time.time() - start_time\n",
    "        return model, load_time, None\n",
    "    except Exception as e:\n",
    "        return None, 0, str(e)\n",
    "\n",
    "def load_evaluation_data(data_file=None):\n",
    "    \"\"\"Carga datos de evaluación\"\"\"\n",
    "    if data_file is None:\n",
    "        data_file = evaluation_data_file\n",
    "    \n",
    "    if os.path.exists(data_file):\n",
    "        try:\n",
    "            print(f\"Cargando datos desde {data_file}\")\n",
    "            if data_file.endswith('.parquet'):\n",
    "                data = pd.read_parquet(data_file)\n",
    "            else:\n",
    "                data = pd.read_csv(data_file)\n",
    "            print(f\"Datos cargados exitosamente: {len(data)} filas\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando {data_file}: {e}\")\n",
    "    \n",
    "    print(f\"No se pudo cargar el archivo de datos: {data_file}\")\n",
    "    return None\n",
    "\n",
    "def create_class_mapping(evaluation_data):\n",
    "    \"\"\"Crea mapeo de clases basado en los datos\"\"\"\n",
    "    if 'clases_modelos' in evaluation_data.columns and 'genus' in evaluation_data.columns:\n",
    "        # Crear mapeo desde genus\n",
    "        mapping_data = evaluation_data[['genus', 'clases_modelos']].drop_duplicates()\n",
    "        class_mapping = dict(zip(mapping_data['clases_modelos'], mapping_data['genus']))\n",
    "        print(f\"Mapeo de clases creado: {len(class_mapping)} clases\")\n",
    "        return class_mapping, evaluation_data\n",
    "    else:\n",
    "        print(\"No se encontraron columnas de clase válidas\")\n",
    "        return None, evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee199e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_unified_metrics(y_true, y_pred, y_proba=None, class_mapping=None):\n",
    "    \"\"\"\n",
    "    Función unificada para calcular métricas detalladas.\n",
    "    Compatible con ambos códigos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Métricas globales - UNIFICADAS\n",
    "    global_metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'f1_score_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'f1_score_macro': f1_score(y_true, y_pred, average='macro'),\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
    "        'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
    "        'precision_weighted': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'precision_macro': precision_score(y_true, y_pred, average='macro'),\n",
    "        'recall_weighted': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'recall_macro': recall_score(y_true, y_pred, average='macro'),\n",
    "        'n_samples': len(y_true),\n",
    "        'n_classes': len(np.unique(y_true))\n",
    "    }\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Métricas por clase\n",
    "    unique_classes = np.unique(y_true)\n",
    "    class_metrics = {\n",
    "        'sensitivity_per_class': {},\n",
    "        'specificity_per_class': {},\n",
    "        'precision_per_class': {},\n",
    "        'recall_per_class': {}\n",
    "    }\n",
    "    \n",
    "    # Si no hay mapeo de clases, crear uno genérico\n",
    "    if class_mapping is None:\n",
    "        class_mapping = {i: f\"Class_{i}\" for i in unique_classes}\n",
    "    \n",
    "    for i, class_id in enumerate(unique_classes):\n",
    "        class_name = class_mapping.get(class_id, f\"Class_{class_id}\")\n",
    "        \n",
    "        # Calcular TP, FP, FN, TN\n",
    "        TP = cm[i, i] if i < cm.shape[0] and i < cm.shape[1] else 0\n",
    "        FP = np.sum(cm[:, i]) - TP if i < cm.shape[1] else 0\n",
    "        FN = np.sum(cm[i, :]) - TP if i < cm.shape[0] else 0\n",
    "        TN = np.sum(cm) - (TP + FP + FN)\n",
    "        \n",
    "        # Métricas por clase\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        class_metrics['sensitivity_per_class'][class_name] = recall\n",
    "        class_metrics['specificity_per_class'][class_name] = specificity\n",
    "        class_metrics['precision_per_class'][class_name] = precision\n",
    "        class_metrics['recall_per_class'][class_name] = recall\n",
    "    \n",
    "    # ROC AUC por clase si hay probabilidades\n",
    "    roc_auc_scores = {}\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            for i, class_id in enumerate(unique_classes):\n",
    "                if i < y_proba.shape[1]:\n",
    "                    class_name = class_mapping.get(class_id, f\"Class_{class_id}\")\n",
    "                    y_true_binary = (y_true == class_id).astype(int)\n",
    "                    \n",
    "                    if len(np.unique(y_true_binary)) > 1:\n",
    "                        fpr, tpr, _ = roc_curve(y_true_binary, y_proba[:, i])\n",
    "                        roc_auc_scores[class_name] = auc(fpr, tpr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculando ROC AUC: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'global_metrics': global_metrics,\n",
    "        'class_metrics': class_metrics,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        # Agregar métricas individuales para compatibilidad\n",
    "        'accuracy': global_metrics['accuracy'],\n",
    "        'f1_score_weighted': global_metrics['f1_score_weighted'],\n",
    "        'f1_score_macro': global_metrics['f1_score_macro'],\n",
    "        'precision_weighted': global_metrics['precision_weighted'],\n",
    "        'precision_macro': global_metrics['precision_macro'],\n",
    "        'recall_weighted': global_metrics['recall_weighted'],\n",
    "        'recall_macro': global_metrics['recall_macro'],\n",
    "        'f1_weighted': global_metrics['f1_weighted'],\n",
    "        'f1_macro': global_metrics['f1_macro'],\n",
    "        'f1_micro': global_metrics['f1_micro'],\n",
    "        'n_samples': global_metrics['n_samples'],\n",
    "        'n_classes': global_metrics['n_classes']\n",
    "    }\n",
    "\n",
    "def calculate_detailed_metrics(y_true, y_pred, y_proba, class_mapping):\n",
    "    \"\"\"Función para el primer código - mantiene la interfaz original\"\"\"\n",
    "    return calculate_unified_metrics(y_true, y_pred, y_proba, class_mapping)\n",
    "\n",
    "def evaluate_single_model(model_info, evaluation_data, class_mapping):\n",
    "    \"\"\"Evalúa un modelo individual - VERSIÓN SIMPLIFICADA MEJORADA\"\"\"\n",
    "    \n",
    "    algorithm = model_info['algorithm']\n",
    "    encoding = model_info['encoding']\n",
    "    model_file = model_info['model_file']\n",
    "    \n",
    "    print(f\"Evaluando {algorithm} - {encoding}\")\n",
    "    \n",
    "    result = {\n",
    "        'algorithm': algorithm,\n",
    "        'encoding': encoding,\n",
    "        'model_file': model_file,\n",
    "        'success': False,\n",
    "        'error': None,\n",
    "        'training_metadata': model_info.get('metadata', {}),\n",
    "        'evaluation_metrics': {},\n",
    "        'timing_info': {},\n",
    "        'memory_info': {},\n",
    "        'predictions': {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if encoding not in evaluation_data.columns:\n",
    "            raise ValueError(f\"Encoding {encoding} no encontrado en datos de evaluación\")\n",
    "        \n",
    "        # Cargar modelo\n",
    "        print(f\"  Cargando modelo...\")\n",
    "        model, load_time, load_error = load_model_safely(model_file)\n",
    "        \n",
    "        if model is None:\n",
    "            raise ValueError(f\"Error cargando modelo: {load_error}\")\n",
    "        \n",
    "        result['timing_info']['model_load_time'] = load_time\n",
    "        \n",
    "        # Preparar datos - FILTRADO MENOS AGRESIVO\n",
    "        print(f\"  Preparando datos...\")\n",
    "        data_prep_start = time.time()\n",
    "        \n",
    "        X_eval_raw = evaluation_data[encoding].tolist()\n",
    "        y_eval_raw = evaluation_data['clases_modelos'].values\n",
    "        \n",
    "        print(f\"  Datos originales: {len(X_eval_raw)} muestras\")\n",
    "        \n",
    "        # CORRECCIÓN: Filtrado más inteligente\n",
    "        valid_indices = []\n",
    "        for i, x in enumerate(X_eval_raw):\n",
    "            is_valid = False\n",
    "            \n",
    "            if x is not None:\n",
    "                if isinstance(x, str) and x.strip() and x.lower() not in ['nan', 'null', 'none']:\n",
    "                    is_valid = True\n",
    "                elif isinstance(x, (list, np.ndarray)) and len(x) > 0:\n",
    "                    if isinstance(x, np.ndarray):\n",
    "                        is_valid = not np.all(np.isnan(x))\n",
    "                    else:\n",
    "                        is_valid = True\n",
    "                elif isinstance(x, (int, float)) and not (np.isnan(x) or np.isinf(x)):\n",
    "                    is_valid = True\n",
    "                else:\n",
    "                    # Intentar convertir otros tipos\n",
    "                    try:\n",
    "                        test_array = np.array(x)\n",
    "                        if test_array.size > 0 and not np.all(np.isnan(test_array)):\n",
    "                            is_valid = True\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            if is_valid:\n",
    "                valid_indices.append(i)\n",
    "        \n",
    "        print(f\"  Datos válidos después de filtrado: {len(valid_indices)}\")\n",
    "        \n",
    "        if len(valid_indices) == 0:\n",
    "            raise ValueError(\"No hay datos válidos para evaluación\")\n",
    "        \n",
    "        X_eval_clean = [X_eval_raw[i] for i in valid_indices]\n",
    "        y_eval_clean = y_eval_raw[valid_indices]\n",
    "        \n",
    "        # Conversión más robusta a numpy array\n",
    "        try:\n",
    "            X_eval_array = np.array(X_eval_clean)\n",
    "            \n",
    "            if X_eval_array.ndim == 1 and len(X_eval_clean) > 0:\n",
    "                first_element = X_eval_clean[0]\n",
    "                if hasattr(first_element, '__len__') and not isinstance(first_element, str):\n",
    "                    try:\n",
    "                        X_eval_array = np.vstack([np.array(x).flatten() for x in X_eval_clean])\n",
    "                    except ValueError:\n",
    "                        # Normalizar a la dimensión más común\n",
    "                        lengths = [len(np.array(x).flatten()) for x in X_eval_clean[:min(100, len(X_eval_clean))]]\n",
    "                        most_common_length = max(set(lengths), key=lengths.count)\n",
    "                        \n",
    "                        X_eval_processed = []\n",
    "                        for x in X_eval_clean:\n",
    "                            x_flat = np.array(x).flatten()\n",
    "                            if len(x_flat) == most_common_length:\n",
    "                                X_eval_processed.append(x_flat)\n",
    "                            elif len(x_flat) > most_common_length:\n",
    "                                X_eval_processed.append(x_flat[:most_common_length])\n",
    "                            else:\n",
    "                                padded = np.zeros(most_common_length)\n",
    "                                padded[:len(x_flat)] = x_flat\n",
    "                                X_eval_processed.append(padded)\n",
    "                        \n",
    "                        X_eval_array = np.vstack(X_eval_processed)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error procesando datos del encoding {encoding}: {e}\")\n",
    "        \n",
    "        print(f\"  Shape final de datos: {X_eval_array.shape}\")\n",
    "        \n",
    "        data_prep_time = time.time() - data_prep_start\n",
    "        result['timing_info']['data_prep_time'] = data_prep_time\n",
    "        \n",
    "        # Información de memoria\n",
    "        result['memory_info'] = {\n",
    "            'input_data_mb': get_memory_usage(X_eval_array),\n",
    "            'original_samples': len(X_eval_raw),\n",
    "            'valid_samples': len(X_eval_clean),\n",
    "            'feature_dimensions': X_eval_array.shape[1] if len(X_eval_array.shape) > 1 else 1\n",
    "        }\n",
    "        \n",
    "        # Hacer predicciones\n",
    "        print(f\"  Realizando predicciones...\")\n",
    "        prediction_start = time.time()\n",
    "        \n",
    "        y_pred = model.predict(X_eval_array)\n",
    "        \n",
    "        # Obtener probabilidades\n",
    "        y_proba = None\n",
    "        try:\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                y_proba = model.predict_proba(X_eval_array)\n",
    "                print(f\"  Probabilidades obtenidas: shape {y_proba.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: No se pudieron obtener probabilidades: {e}\")\n",
    "        \n",
    "        prediction_time = time.time() - prediction_start\n",
    "        result['timing_info']['prediction_time'] = prediction_time\n",
    "        result['timing_info']['total_time'] = load_time + data_prep_time + prediction_time\n",
    "        \n",
    "        # Calcular métricas\n",
    "        print(f\"  Calculando métricas...\")\n",
    "        metrics_start = time.time()\n",
    "        \n",
    "        detailed_metrics = calculate_unified_metrics(y_eval_clean, y_pred, y_proba, class_mapping)\n",
    "        \n",
    "        metrics_time = time.time() - metrics_start\n",
    "        result['timing_info']['metrics_calc_time'] = metrics_time\n",
    "        \n",
    "        result['evaluation_metrics'] = detailed_metrics\n",
    "        \n",
    "        # CORRECCIÓN CLAVE: Guardar TODAS las predicciones para visualización\n",
    "        result['predictions'] = {\n",
    "            'y_true': y_eval_clean.tolist(),\n",
    "            'y_pred': y_pred.tolist(),\n",
    "            'y_proba': y_proba.tolist() if y_proba is not None else None,\n",
    "            'correct_predictions': (y_eval_clean == y_pred).tolist(),\n",
    "            'accuracy': detailed_metrics['accuracy'],\n",
    "            'n_samples_used': len(y_eval_clean),\n",
    "            'n_samples_original': len(X_eval_raw)\n",
    "        }\n",
    "        \n",
    "        if result['timing_info']['total_time'] > 0:\n",
    "            result['efficiency_score'] = detailed_metrics['accuracy'] / result['timing_info']['total_time']\n",
    "        else:\n",
    "            result['efficiency_score'] = 0\n",
    "        \n",
    "        result['success'] = True\n",
    "        \n",
    "        print(f\"  Completado - Accuracy: {detailed_metrics['accuracy']:.4f}, \"\n",
    "              f\"F1 Weighted: {detailed_metrics['f1_score_weighted']:.4f}, \"\n",
    "              f\"Muestras utilizadas: {len(y_eval_clean)}/{len(X_eval_raw)}\")\n",
    "        \n",
    "        # Liberar memoria\n",
    "        if MEMORY_EFFICIENT:\n",
    "            del model, X_eval_array, y_pred\n",
    "            if y_proba is not None:\n",
    "                del y_proba\n",
    "            gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['error'] = str(e)\n",
    "        print(f\"  Error: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def save_evaluation_results(all_results, results_dir=None):\n",
    "    \"\"\"Versión mejorada del guardado - OPCIONAL\"\"\"\n",
    "    \n",
    "    if results_dir is None:\n",
    "        results_dir = evaluation_results_dir\n",
    "    \n",
    "    # Crear DataFrame principal\n",
    "    main_data = []\n",
    "    for result in all_results:\n",
    "        if result['success']:\n",
    "            metrics = result['evaluation_metrics']\n",
    "            timing = result['timing_info']\n",
    "            memory = result['memory_info']\n",
    "            predictions = result.get('predictions', {})\n",
    "            \n",
    "            row = {\n",
    "                'algorithm': result['algorithm'],\n",
    "                'encoding': result['encoding'],\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'f1_weighted': metrics['f1_weighted'],\n",
    "                'f1_score_weighted': metrics['f1_score_weighted'],\n",
    "                'f1_macro': metrics['f1_macro'],\n",
    "                'f1_score_macro': metrics['f1_score_macro'],\n",
    "                'f1_micro': metrics['f1_micro'],\n",
    "                'precision_weighted': metrics['precision_weighted'],\n",
    "                'precision_macro': metrics['precision_macro'],\n",
    "                'recall_weighted': metrics['recall_weighted'], \n",
    "                'recall_macro': metrics['recall_macro'], \n",
    "                'n_samples': metrics['n_samples'],\n",
    "                'n_classes': metrics['n_classes'],\n",
    "                'total_time': timing['total_time'],\n",
    "                'prediction_time': timing['prediction_time'],\n",
    "                'model_load_time': timing['model_load_time'],\n",
    "                'efficiency_score': result['efficiency_score'],\n",
    "                'input_data_mb': memory['input_data_mb'],\n",
    "                'feature_dimensions': memory['feature_dimensions'],\n",
    "                'model_file': result['model_file'],\n",
    "                # NUEVO: Información de muestras\n",
    "                'valid_samples': predictions.get('n_samples_used', memory.get('valid_samples', 0)),\n",
    "                'original_samples': predictions.get('n_samples_original', memory.get('original_samples', 0)),\n",
    "                'has_probabilities': predictions.get('y_proba') is not None\n",
    "            }\n",
    "            main_data.append(row)\n",
    "    \n",
    "    if not main_data:\n",
    "        print(\"No hay resultados exitosos para guardar\")\n",
    "        return None\n",
    "    \n",
    "    df_main = pd.DataFrame(main_data)\n",
    "    \n",
    "    # Guardar CSV principal\n",
    "    csv_path = os.path.join(results_dir, csv_output_filename)\n",
    "    df_main.to_csv(csv_path, index=False)\n",
    "    print(f\"Resultados principales guardados: {csv_path}\")\n",
    "    \n",
    "    # Guardar Excel con múltiples hojas\n",
    "    excel_path = os.path.join(results_dir, excel_output_filename)\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        df_main.to_excel(writer, sheet_name='Resumen', index=False)\n",
    "        \n",
    "        # Métricas por clase\n",
    "        class_data = []\n",
    "        for result in all_results:\n",
    "            if result['success'] and result['evaluation_metrics']['class_metrics']:\n",
    "                for class_name in result['evaluation_metrics']['class_metrics']['precision_per_class'].keys():\n",
    "                    row = {\n",
    "                        'algorithm': result['algorithm'],\n",
    "                        'encoding': result['encoding'],\n",
    "                        'class_name': class_name,\n",
    "                        'precision': result['evaluation_metrics']['class_metrics']['precision_per_class'][class_name],\n",
    "                        'recall': result['evaluation_metrics']['class_metrics']['recall_per_class'][class_name],\n",
    "                        'sensitivity': result['evaluation_metrics']['class_metrics']['sensitivity_per_class'][class_name],\n",
    "                        'specificity': result['evaluation_metrics']['class_metrics']['specificity_per_class'][class_name]\n",
    "                    }\n",
    "                    class_data.append(row)\n",
    "        \n",
    "        if class_data:\n",
    "            df_class = pd.DataFrame(class_data)\n",
    "            df_class.to_excel(writer, sheet_name='Metricas_por_Clase', index=False)\n",
    "        \n",
    "        # Timing\n",
    "        timing_data = []\n",
    "        for result in all_results:\n",
    "            if result['success']:\n",
    "                row = {\n",
    "                    'algorithm': result['algorithm'],\n",
    "                    'encoding': result['encoding'],\n",
    "                    **result['timing_info']\n",
    "                }\n",
    "                timing_data.append(row)\n",
    "        \n",
    "        if timing_data:\n",
    "            df_timing = pd.DataFrame(timing_data)\n",
    "            df_timing.to_excel(writer, sheet_name='Tiempos_Ejecucion', index=False)\n",
    "    \n",
    "    print(f\"Excel completo guardado: {excel_path}\")\n",
    "    \n",
    "    # Guardar JSON CON todas las predicciones\n",
    "    json_path = os.path.join(results_dir, json_output_filename)\n",
    "    \n",
    "    json_data = {\n",
    "        'total_models': len(all_results),\n",
    "        'successful_evaluations': len([r for r in all_results if r['success']]),\n",
    "        'failed_evaluations': len([r for r in all_results if not r['success']]),\n",
    "        'results': []\n",
    "    }\n",
    "    \n",
    "    # CLAVE: Incluir TODAS las predicciones en el JSON\n",
    "    for result in all_results:\n",
    "        if result['success']:\n",
    "            json_result = {\n",
    "                'algorithm': result['algorithm'],\n",
    "                'encoding': result['encoding'],\n",
    "                'model_file': result['model_file'],\n",
    "                'success': result['success'],\n",
    "                'accuracy': float(result['evaluation_metrics']['accuracy']),\n",
    "                'f1_weighted': float(result['evaluation_metrics']['f1_weighted']),\n",
    "                'f1_macro': float(result['evaluation_metrics']['f1_macro']),\n",
    "                'precision_weighted': float(result['evaluation_metrics']['precision_weighted']),\n",
    "                'precision_macro': float(result['evaluation_metrics']['precision_macro']),\n",
    "                'recall_weighted': float(result['evaluation_metrics']['recall_weighted']),\n",
    "                'recall_macro': float(result['evaluation_metrics']['recall_macro']),\n",
    "                'total_time': float(result['timing_info']['total_time']),\n",
    "                'efficiency_score': float(result['efficiency_score']),\n",
    "                # CLAVE: Incluir todas las predicciones\n",
    "                'predictions': result.get('predictions', {}),\n",
    "                'evaluation_metrics': {\n",
    "                    'class_metrics': result['evaluation_metrics'].get('class_metrics', {}),\n",
    "                    'confusion_matrix': result['evaluation_metrics'].get('confusion_matrix', None),\n",
    "                    'roc_auc_scores': result['evaluation_metrics'].get('roc_auc_scores', {})\n",
    "                }\n",
    "            }\n",
    "            json_data['results'].append(json_result)\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(json_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"JSON guardado: {json_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error guardando JSON: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'csv_path': csv_path,\n",
    "        'excel_path': excel_path,\n",
    "        'json_path': json_path,\n",
    "        'main_dataframe': df_main\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f74177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando modelos...\n",
      "Cargando modelos desde 'modelos'\n",
      "  Encontrado: SVM - PS_K-mers + FFT\n",
      "  Encontrado: SVM - PS_FFT\n",
      "  Encontrado: SVM - AS_K-mers + Wavelet\n",
      "  Encontrado: SVM - PS_One Hot + FFT\n",
      "  Encontrado: SVM - AS_One Hot + Wavelet\n",
      "  Encontrado: SVM - PS_K-mers\n",
      "  Encontrado: SVM - PS_One Hot\n",
      "  Encontrado: SVM - AS_One Hot\n",
      "  Encontrado: SVM - AS_K-mers\n",
      "  Encontrado: SVM - AS_One Hot + FFT\n",
      "  Encontrado: SVM - PS_K-mers + Wavelet\n",
      "  Encontrado: SVM - AS_K-mers + FFT\n",
      "  Encontrado: SVM - PS_Wavelet\n",
      "  Encontrado: SVM - AS_FFT\n",
      "  Encontrado: SVM - PS_One Hot + Wavelet\n",
      "  Encontrado: SVM - AS_Wavelet\n",
      "  Encontrado: RandomForest - PS_K-mers + FFT\n",
      "  Encontrado: RandomForest - PS_FFT\n",
      "  Encontrado: RandomForest - AS_K-mers + Wavelet\n",
      "  Encontrado: RandomForest - PS_One Hot + FFT\n",
      "  Encontrado: RandomForest - AS_One Hot + Wavelet\n",
      "  Encontrado: RandomForest - PS_K-mers\n",
      "  Encontrado: RandomForest - PS_One Hot\n",
      "  Encontrado: RandomForest - AS_One Hot\n",
      "  Encontrado: RandomForest - AS_K-mers\n",
      "  Encontrado: RandomForest - AS_One Hot + FFT\n",
      "  Encontrado: RandomForest - PS_K-mers + Wavelet\n",
      "  Encontrado: RandomForest - AS_K-mers + FFT\n",
      "  Encontrado: RandomForest - PS_Wavelet\n",
      "  Encontrado: RandomForest - AS_FFT\n",
      "  Encontrado: RandomForest - PS_One Hot + Wavelet\n",
      "  Encontrado: RandomForest - AS_Wavelet\n",
      "  Encontrado: XGBoost - PS_K-mers + FFT\n",
      "  Encontrado: XGBoost - PS_FFT\n",
      "  Encontrado: XGBoost - AS_K-mers + Wavelet\n",
      "  Encontrado: XGBoost - PS_One Hot + FFT\n",
      "  Encontrado: XGBoost - AS_One Hot + Wavelet\n",
      "  Encontrado: XGBoost - PS_K-mers\n",
      "  Encontrado: XGBoost - PS_One Hot\n",
      "  Encontrado: XGBoost - AS_One Hot\n",
      "  Encontrado: XGBoost - AS_K-mers\n",
      "  Encontrado: XGBoost - AS_One Hot + FFT\n",
      "  Encontrado: XGBoost - PS_K-mers + Wavelet\n",
      "  Encontrado: XGBoost - AS_K-mers + FFT\n",
      "  Encontrado: XGBoost - PS_Wavelet\n",
      "  Encontrado: XGBoost - AS_FFT\n",
      "  Encontrado: XGBoost - PS_One Hot + Wavelet\n",
      "  Encontrado: XGBoost - AS_Wavelet\n",
      "Total de modelos descubiertos: 48\n",
      "Cargando datos de evaluación...\n",
      "Cargando datos desde datos/evaluation_data.parquet\n",
      "Datos cargados exitosamente: 8555 filas\n",
      "Mapeando clases...\n",
      "Mapeo de clases creado: 29 clases\n",
      "Datos cargados: 8555 muestras, 29 clases\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Buscando modelos...\")\n",
    "# Descubrir modelos\n",
    "discovered_models = discover_models(\"modelos\")  # Cambia la ruta según tu estructura\n",
    "\n",
    "print(\"Cargando datos de evaluación...\")\n",
    "# Cargar datos de evaluación\n",
    "evaluation_data = load_evaluation_data(\"datos/evaluation_data.parquet\")\n",
    "\n",
    "print(\"Mapeando clases...\")\n",
    "class_mapping, evaluation_data = create_class_mapping(evaluation_data)\n",
    "\n",
    "if class_mapping is None:\n",
    "    print(\"Error: No se pudo crear el mapeo de clases\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Datos cargados: {len(evaluation_data)} muestras, {len(class_mapping)} clases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f51fd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando evaluación de modelos...\n",
      "Progreso: 1/48\n",
      "Evaluando SVM - PS_K-mers + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 798)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9582, F1 Weighted: 0.9578, Muestras utilizadas: 8555/8555\n",
      "Progreso: 2/48\n",
      "Evaluando SVM - PS_FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 799)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9607, F1 Weighted: 0.9600, Muestras utilizadas: 8555/8555\n",
      "Progreso: 3/48\n",
      "Evaluando SVM - AS_K-mers + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7839)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9949, F1 Weighted: 0.9949, Muestras utilizadas: 8555/8555\n",
      "Progreso: 4/48\n",
      "Evaluando SVM - PS_One Hot + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3999)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9528, F1 Weighted: 0.9544, Muestras utilizadas: 8555/8555\n",
      "Progreso: 5/48\n",
      "Evaluando SVM - AS_One Hot + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 39189)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9952, F1 Weighted: 0.9952, Muestras utilizadas: 8555/8555\n",
      "Progreso: 6/48\n",
      "Evaluando SVM - PS_K-mers\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1598)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3280, F1 Weighted: 0.3610, Muestras utilizadas: 8555/8555\n",
      "Progreso: 7/48\n",
      "Evaluando SVM - PS_One Hot\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 8000)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3177, F1 Weighted: 0.3469, Muestras utilizadas: 8555/8555\n",
      "Progreso: 8/48\n",
      "Evaluando SVM - AS_One Hot\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 39180)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9953, F1 Weighted: 0.9953, Muestras utilizadas: 8555/8555\n",
      "Progreso: 9/48\n",
      "Evaluando SVM - AS_K-mers\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7834)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9952, F1 Weighted: 0.9952, Muestras utilizadas: 8555/8555\n",
      "Progreso: 10/48\n",
      "Evaluando SVM - AS_One Hot + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 19589)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9952, F1 Weighted: 0.9952, Muestras utilizadas: 8555/8555\n",
      "Progreso: 11/48\n",
      "Evaluando SVM - PS_K-mers + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1602)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3328, F1 Weighted: 0.3628, Muestras utilizadas: 8555/8555\n",
      "Progreso: 12/48\n",
      "Evaluando SVM - AS_K-mers + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3916)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9918, F1 Weighted: 0.9918, Muestras utilizadas: 8555/8555\n",
      "Progreso: 13/48\n",
      "Evaluando SVM - PS_Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1603)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3395, F1 Weighted: 0.3676, Muestras utilizadas: 8555/8555\n",
      "Progreso: 14/48\n",
      "Evaluando SVM - AS_FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3917)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9949, F1 Weighted: 0.9949, Muestras utilizadas: 8555/8555\n",
      "Progreso: 15/48\n",
      "Evaluando SVM - PS_One Hot + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 8002)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3179, F1 Weighted: 0.3472, Muestras utilizadas: 8555/8555\n",
      "Progreso: 16/48\n",
      "Evaluando SVM - AS_Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7840)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9917, F1 Weighted: 0.9917, Muestras utilizadas: 8555/8555\n",
      "Progreso: 17/48\n",
      "Evaluando RandomForest - PS_K-mers + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 798)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9093, F1 Weighted: 0.9159, Muestras utilizadas: 8555/8555\n",
      "Progreso: 18/48\n",
      "Evaluando RandomForest - PS_FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 799)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9303, F1 Weighted: 0.9334, Muestras utilizadas: 8555/8555\n",
      "Progreso: 19/48\n",
      "Evaluando RandomForest - AS_K-mers + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7839)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9945, F1 Weighted: 0.9945, Muestras utilizadas: 8555/8555\n",
      "Progreso: 20/48\n",
      "Evaluando RandomForest - PS_One Hot + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3999)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.7895, F1 Weighted: 0.8236, Muestras utilizadas: 8555/8555\n",
      "Progreso: 21/48\n",
      "Evaluando RandomForest - AS_One Hot + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 39189)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9922, F1 Weighted: 0.9922, Muestras utilizadas: 8555/8555\n",
      "Progreso: 22/48\n",
      "Evaluando RandomForest - PS_K-mers\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1598)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3627, F1 Weighted: 0.4028, Muestras utilizadas: 8555/8555\n",
      "Progreso: 23/48\n",
      "Evaluando RandomForest - PS_One Hot\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 8000)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.2852, F1 Weighted: 0.3094, Muestras utilizadas: 8555/8555\n",
      "Progreso: 24/48\n",
      "Evaluando RandomForest - AS_One Hot\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 39180)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9921, F1 Weighted: 0.9920, Muestras utilizadas: 8555/8555\n",
      "Progreso: 25/48\n",
      "Evaluando RandomForest - AS_K-mers\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7834)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9945, F1 Weighted: 0.9945, Muestras utilizadas: 8555/8555\n",
      "Progreso: 26/48\n",
      "Evaluando RandomForest - AS_One Hot + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 19589)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9895, F1 Weighted: 0.9895, Muestras utilizadas: 8555/8555\n",
      "Progreso: 27/48\n",
      "Evaluando RandomForest - PS_K-mers + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1602)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3862, F1 Weighted: 0.4278, Muestras utilizadas: 8555/8555\n",
      "Progreso: 28/48\n",
      "Evaluando RandomForest - AS_K-mers + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3916)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9897, F1 Weighted: 0.9897, Muestras utilizadas: 8555/8555\n",
      "Progreso: 29/48\n",
      "Evaluando RandomForest - PS_Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1603)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3841, F1 Weighted: 0.4219, Muestras utilizadas: 8555/8555\n",
      "Progreso: 30/48\n",
      "Evaluando RandomForest - AS_FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3917)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9915, F1 Weighted: 0.9915, Muestras utilizadas: 8555/8555\n",
      "Progreso: 31/48\n",
      "Evaluando RandomForest - PS_One Hot + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 8002)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.2919, F1 Weighted: 0.3193, Muestras utilizadas: 8555/8555\n",
      "Progreso: 32/48\n",
      "Evaluando RandomForest - AS_Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7840)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9945, F1 Weighted: 0.9945, Muestras utilizadas: 8555/8555\n",
      "Progreso: 33/48\n",
      "Evaluando XGBoost - PS_K-mers + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 798)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.8677, F1 Weighted: 0.8838, Muestras utilizadas: 8555/8555\n",
      "Progreso: 34/48\n",
      "Evaluando XGBoost - PS_FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 799)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9255, F1 Weighted: 0.9271, Muestras utilizadas: 8555/8555\n",
      "Progreso: 35/48\n",
      "Evaluando XGBoost - AS_K-mers + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7839)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9931, F1 Weighted: 0.9931, Muestras utilizadas: 8555/8555\n",
      "Progreso: 36/48\n",
      "Evaluando XGBoost - PS_One Hot + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3999)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.8627, F1 Weighted: 0.8810, Muestras utilizadas: 8555/8555\n",
      "Progreso: 37/48\n",
      "Evaluando XGBoost - AS_One Hot + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 39189)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9870, F1 Weighted: 0.9868, Muestras utilizadas: 8555/8555\n",
      "Progreso: 38/48\n",
      "Evaluando XGBoost - PS_K-mers\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1598)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.3100, F1 Weighted: 0.3398, Muestras utilizadas: 8555/8555\n",
      "Progreso: 39/48\n",
      "Evaluando XGBoost - PS_One Hot\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 8000)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.2663, F1 Weighted: 0.2882, Muestras utilizadas: 8555/8555\n",
      "Progreso: 40/48\n",
      "Evaluando XGBoost - AS_One Hot\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 39180)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9944, F1 Weighted: 0.9944, Muestras utilizadas: 8555/8555\n",
      "Progreso: 41/48\n",
      "Evaluando XGBoost - AS_K-mers\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7834)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9942, F1 Weighted: 0.9942, Muestras utilizadas: 8555/8555\n",
      "Progreso: 42/48\n",
      "Evaluando XGBoost - AS_One Hot + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 19589)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9918, F1 Weighted: 0.9918, Muestras utilizadas: 8555/8555\n",
      "Progreso: 43/48\n",
      "Evaluando XGBoost - PS_K-mers + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1602)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.4359, F1 Weighted: 0.4634, Muestras utilizadas: 8555/8555\n",
      "Progreso: 44/48\n",
      "Evaluando XGBoost - AS_K-mers + FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3916)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9870, F1 Weighted: 0.9870, Muestras utilizadas: 8555/8555\n",
      "Progreso: 45/48\n",
      "Evaluando XGBoost - PS_Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 1603)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.4137, F1 Weighted: 0.4264, Muestras utilizadas: 8555/8555\n",
      "Progreso: 46/48\n",
      "Evaluando XGBoost - AS_FFT\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 3917)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9904, F1 Weighted: 0.9904, Muestras utilizadas: 8555/8555\n",
      "Progreso: 47/48\n",
      "Evaluando XGBoost - PS_One Hot + Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 8002)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.2822, F1 Weighted: 0.3099, Muestras utilizadas: 8555/8555\n",
      "Progreso: 48/48\n",
      "Evaluando XGBoost - AS_Wavelet\n",
      "  Cargando modelo...\n",
      "  Preparando datos...\n",
      "  Datos originales: 8555 muestras\n",
      "  Datos válidos después de filtrado: 8555\n",
      "  Shape final de datos: (8555, 7840)\n",
      "  Realizando predicciones...\n",
      "  Probabilidades obtenidas: shape (8555, 29)\n",
      "  Calculando métricas...\n",
      "  Completado - Accuracy: 0.9931, F1 Weighted: 0.9931, Muestras utilizadas: 8555/8555\n",
      "Evaluación completada: 48 exitosos, 0 fallidos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluar modelos\n",
    "print(\"Iniciando evaluación de modelos...\")\n",
    "\n",
    "all_results = []\n",
    "successful_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "total_models = len(discovered_models)\n",
    "\n",
    "for i, model_info in enumerate(discovered_models):\n",
    "    print(f\"Progreso: {i+1}/{total_models}\")\n",
    "    \n",
    "    # Verificar que el archivo existe\n",
    "    if not os.path.exists(model_info['model_file']):\n",
    "        print(f\"Archivo no encontrado: {model_info['model_file']}\")\n",
    "        failed_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    result = evaluate_single_model(model_info, evaluation_data, class_mapping)\n",
    "    all_results.append(result)\n",
    "    \n",
    "    if result['success']:\n",
    "        successful_count += 1\n",
    "    else:\n",
    "        failed_count += 1\n",
    "    \n",
    "    # Liberar memoria cada ciertos modelos\n",
    "    if MEMORY_EFFICIENT and i % MAX_MODELS_IN_MEMORY == 0:\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"Evaluación completada: {successful_count} exitosos, {failed_count} fallidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56eb4923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando resultados...\n",
      "Resultados principales guardados: results/evaluation_results/evaluation_results.csv\n",
      "Excel completo guardado: results/evaluation_results/evaluation_complete.xlsx\n",
      "JSON guardado: results/evaluation_results/evaluation_detailed.json\n",
      "\n",
      "============================================================\n",
      "EVALUACIÓN COMPLETADA\n",
      "============================================================\n",
      "Modelos evaluados exitosamente: 48\n",
      "Modelos fallidos: 0\n",
      "Total procesados: 48\n",
      "\n",
      "MEJORES RESULTADOS:\n",
      "Mejor accuracy: 0.9953\n",
      "Accuracy promedio: 0.7715\n",
      "Mejor F1 weighted: 0.9953\n",
      "Mejor precision macro: 0.9955\n",
      "Mejor eficiencia: 4.7688\n",
      "\n",
      "MEJOR MODELO:\n",
      "  Algoritmo: SVM\n",
      "  Encoding: AS_One Hot\n",
      "  Accuracy: 0.9953\n",
      "  F1 Weighted: 0.9953\n",
      "  Precision Macro: 0.9955\n",
      "  Tiempo: 565.57s\n",
      "\n",
      "ARCHIVOS GENERADOS:\n",
      "  csv_path: results/evaluation_results/evaluation_results.csv\n",
      "  excel_path: results/evaluation_results/evaluation_complete.xlsx\n",
      "  json_path: results/evaluation_results/evaluation_detailed.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Guardar resultados\n",
    "print(\"Guardando resultados...\")\n",
    "saved_files = save_evaluation_results(all_results)\n",
    "\n",
    "# Resumen final\n",
    "if saved_files and 'main_dataframe' in saved_files:\n",
    "    df = saved_files['main_dataframe']\n",
    "    if not df.empty:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EVALUACIÓN COMPLETADA\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Modelos evaluados exitosamente: {successful_count}\")\n",
    "        print(f\"Modelos fallidos: {failed_count}\")\n",
    "        print(f\"Total procesados: {len(all_results)}\")\n",
    "        print(f\"\\nMEJORES RESULTADOS:\")\n",
    "        print(f\"Mejor accuracy: {df['accuracy'].max():.4f}\")\n",
    "        print(f\"Accuracy promedio: {df['accuracy'].mean():.4f}\")\n",
    "        print(f\"Mejor F1 weighted: {df['f1_weighted'].max():.4f}\")\n",
    "        print(f\"Mejor precision macro: {df['precision_macro'].max():.4f}\")\n",
    "        print(f\"Mejor eficiencia: {df['efficiency_score'].max():.4f}\")\n",
    "        \n",
    "        best_model = df.loc[df['accuracy'].idxmax()]\n",
    "        print(f\"\\nMEJOR MODELO:\")\n",
    "        print(f\"  Algoritmo: {best_model['algorithm']}\")\n",
    "        print(f\"  Encoding: {best_model['encoding']}\")\n",
    "        print(f\"  Accuracy: {best_model['accuracy']:.4f}\")\n",
    "        print(f\"  F1 Weighted: {best_model['f1_weighted']:.4f}\")\n",
    "        print(f\"  Precision Macro: {best_model['precision_macro']:.4f}\")\n",
    "        print(f\"  Tiempo: {best_model['total_time']:.2f}s\")\n",
    "        \n",
    "        print(f\"\\nARCHIVOS GENERADOS:\")\n",
    "        for key, path in saved_files.items():\n",
    "            if key != 'main_dataframe':\n",
    "                print(f\"  {key}: {path}\")\n",
    "        print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
