{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057f40b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Distribución de secuencias por género bacteriano, origen y propósito}\n",
      "\\label{tab:dataset_distribution}\n",
      "\\setlength{\\tabcolsep}{4pt}\n",
      "\\renewcommand{\\arraystretch}{1.2}\n",
      "\\begin{tabular}{l|cc|cc|c|c}\n",
      "\\hline\n",
      "& \\multicolumn{2}{c|}{\\textbf{Train}} & \\multicolumn{2}{c|}{\\textbf{Test}} & & \\\\\n",
      "\\textbf{Género} & \\textbf{GTDB} & \\textbf{Entrez} & \\textbf{GTDB} & \\textbf{Entrez} & \\textbf{Leftover} & \\textbf{Total} \\\\\n",
      "\\hline\n",
      "Acinetobacter & 160 & 40 & 9 & 291 & 564 & 1064 \\\\\n",
      "Arthrobacter & 167 & 33 & 6 & 294 & 625 & 1125 \\\\\n",
      "Bifidobacterium & 120 & 80 & 4 & 296 & 543 & 1043 \\\\\n",
      "Bradyrhizobium & 181 & 19 & 48 & 252 & 683 & 1183 \\\\\n",
      "Chryseobacterium & 128 & 72 & 41 & 259 & 558 & 1058 \\\\\n",
      "Collinsella & 139 & 61 & 9 & 207 & -- & 416 \\\\\n",
      "Corynebacterium & 132 & 68 & 58 & 242 & 558 & 1058 \\\\\n",
      "Flavobacterium & 185 & 15 & 147 & 153 & 744 & 1244 \\\\\n",
      "Mesorhizobium & 141 & 59 & -- & 300 & 587 & 1087 \\\\\n",
      "Methylobacterium & 93 & 107 & 4 & 296 & 501 & 1001 \\\\\n",
      "Microbacterium & 177 & 23 & 103 & 197 & 728 & 1228 \\\\\n",
      "Micromonospora & 142 & 58 & 1 & 299 & 582 & 1082 \\\\\n",
      "Mycobacterium & 134 & 66 & 236 & 64 & 808 & 1308 \\\\\n",
      "Nocardia & 130 & 70 & 1 & 299 & 541 & 1041 \\\\\n",
      "Nocardioides & 164 & 36 & 2 & 298 & 558 & 1058 \\\\\n",
      "Novosphingobium & 98 & 102 & 2 & 298 & 398 & 898 \\\\\n",
      "Paraburkholderia & 111 & 89 & 4 & 296 & 433 & 933 \\\\\n",
      "Paracoccus & 100 & 100 & 2 & 298 & 547 & 1047 \\\\\n",
      "Pedobacter & 105 & 95 & -- & 300 & 524 & 1024 \\\\\n",
      "Pelagibacter & 188 & 12 & 300 & -- & 497 & 997 \\\\\n",
      "Polynucleobacter & 112 & 88 & 1 & 299 & 239 & 739 \\\\\n",
      "Prevotella & 96 & 104 & -- & 300 & 233 & 733 \\\\\n",
      "Prochlorococcus & 198 & 2 & 46 & 193 & -- & 439 \\\\\n",
      "Pseudomonas & 175 & 25 & 300 & -- & 1119 & 1619 \\\\\n",
      "Rhizobium & 147 & 53 & 2 & 298 & 587 & 1087 \\\\\n",
      "Sphingomonas & 180 & 20 & 42 & 258 & 640 & 1140 \\\\\n",
      "Streptococcus & 182 & 18 & 253 & 47 & 901 & 1401 \\\\\n",
      "Streptomyces & 157 & 43 & 261 & 39 & 1355 & 1855 \\\\\n",
      "Vibrio & 158 & 42 & 16 & 284 & 502 & 1002 \\\\\n",
      "\\hline\n",
      "\\textbf{Total} & \\textbf{4200} & \\textbf{1600} & \\textbf{1898} & \\textbf{6657} & \\textbf{16555} & \\textbf{30910} \\\\\n",
      "\\hline\n",
      "\\multicolumn{7}{l}{\\textbf{Distribución: 29 géneros bacterianos procesados}} \\\\\n",
      "\\multicolumn{7}{l}{\\textbf{Total entrenamiento: 5,800 secuencias}} \\\\\n",
      "\\multicolumn{7}{l}{\\textbf{Total evaluación: 8,555 secuencias}} \\\\\n",
      "\\multicolumn{7}{l}{\\textbf{Total utilizadas: 14,355 secuencias}} \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('datos/datos_filtrados_sin_encoding.csv')\n",
    "\n",
    "# Crear directorio si no existe\n",
    "if not os.path.exists('latex_tables'):\n",
    "    os.makedirs('latex_tables')\n",
    "\n",
    "# Crear tabla de contingencia\n",
    "combined_data = []\n",
    "\n",
    "for genus in sorted(df['genus'].unique()):\n",
    "    genus_data = df[df['genus'] == genus]\n",
    "    \n",
    "    # Train por origen\n",
    "    train_gtdb = len(genus_data[(genus_data['purpose'] == 0) & (genus_data['origen'] == 'gtdb')])\n",
    "    train_entrez = len(genus_data[(genus_data['purpose'] == 0) & (genus_data['origen'] == 'entrez')])\n",
    "    \n",
    "    # Test por origen\n",
    "    test_gtdb = len(genus_data[(genus_data['purpose'] == 1) & (genus_data['origen'] == 'gtdb')])\n",
    "    test_entrez = len(genus_data[(genus_data['purpose'] == 1) & (genus_data['origen'] == 'entrez')])\n",
    "    \n",
    "    # Descartados\n",
    "    leftover = len(genus_data[genus_data['purpose'] == 2])\n",
    "    \n",
    "    # Total\n",
    "    total = len(genus_data)\n",
    "    \n",
    "    combined_data.append({\n",
    "        'genus': genus,\n",
    "        'train_gtdb': train_gtdb,\n",
    "        'train_entrez': train_entrez,\n",
    "        'test_gtdb': test_gtdb,\n",
    "        'test_entrez': test_entrez,\n",
    "        'leftover': leftover,\n",
    "        'total': total\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame\n",
    "table_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Calcular totales\n",
    "totals = {\n",
    "    'train_gtdb': table_df['train_gtdb'].sum(),\n",
    "    'train_entrez': table_df['train_entrez'].sum(),\n",
    "    'test_gtdb': table_df['test_gtdb'].sum(),\n",
    "    'test_entrez': table_df['test_entrez'].sum(),\n",
    "    'leftover': table_df['leftover'].sum(),\n",
    "    'total': table_df['total'].sum()\n",
    "}\n",
    "\n",
    "# Generar código LaTeX\n",
    "latex_lines = [\n",
    "    \"\\\\begin{table}[htbp]\",\n",
    "    \"\\\\centering\",\n",
    "    \"\\\\caption{Distribución de secuencias por género bacteriano, origen y propósito}\",\n",
    "    \"\\\\label{tab:dataset_distribution}\",\n",
    "    \"\\\\setlength{\\\\tabcolsep}{4pt}\",\n",
    "    \"\\\\renewcommand{\\\\arraystretch}{1.2}\",\n",
    "    \"\\\\begin{tabular}{l|cc|cc|c|c}\",\n",
    "    \"\\\\hline\",\n",
    "    \"& \\\\multicolumn{2}{c|}{\\\\textbf{Train}} & \\\\multicolumn{2}{c|}{\\\\textbf{Test}} & & \\\\\\\\\",\n",
    "    \"\\\\textbf{Género} & \\\\textbf{GTDB} & \\\\textbf{Entrez} & \\\\textbf{GTDB} & \\\\textbf{Entrez} & \\\\textbf{Leftover} & \\\\textbf{Total} \\\\\\\\\",\n",
    "    \"\\\\hline\"\n",
    "]\n",
    "\n",
    "# Agregar filas de datos\n",
    "for _, row in table_df.iterrows():\n",
    "    genus = row['genus'].replace('_', '\\\\_')\n",
    "    train_gtdb = row['train_gtdb'] if row['train_gtdb'] > 0 else '--'\n",
    "    train_entrez = row['train_entrez'] if row['train_entrez'] > 0 else '--'\n",
    "    test_gtdb = row['test_gtdb'] if row['test_gtdb'] > 0 else '--'\n",
    "    test_entrez = row['test_entrez'] if row['test_entrez'] > 0 else '--'\n",
    "    leftover = row['leftover'] if row['leftover'] > 0 else '--'\n",
    "    total = row['total']\n",
    "    \n",
    "    latex_lines.append(f\"{genus} & {train_gtdb} & {train_entrez} & {test_gtdb} & {test_entrez} & {leftover} & {total} \\\\\\\\\")\n",
    "\n",
    "# Calcular estadísticas para la tabla\n",
    "total_genera = len(table_df)\n",
    "total_train = totals['train_gtdb'] + totals['train_entrez']\n",
    "total_test = totals['test_gtdb'] + totals['test_entrez']\n",
    "total_used = total_train + total_test\n",
    "\n",
    "# Agregar totales y estadísticas dentro de la tabla\n",
    "latex_lines.extend([\n",
    "    \"\\\\hline\",\n",
    "    f\"\\\\textbf{{Total}} & \\\\textbf{{{totals['train_gtdb']}}} & \\\\textbf{{{totals['train_entrez']}}} & \\\\textbf{{{totals['test_gtdb']}}} & \\\\textbf{{{totals['test_entrez']}}} & \\\\textbf{{{totals['leftover']}}} & \\\\textbf{{{totals['total']}}} \\\\\\\\\",\n",
    "    \"\\\\hline\",\n",
    "    f\"\\\\multicolumn{{7}}{{l}}{{\\\\textbf{{Distribución: {total_genera} géneros bacterianos procesados}}}} \\\\\\\\\",\n",
    "    f\"\\\\multicolumn{{7}}{{l}}{{\\\\textbf{{Total entrenamiento: {total_train:,} secuencias}}}} \\\\\\\\\",\n",
    "    f\"\\\\multicolumn{{7}}{{l}}{{\\\\textbf{{Total evaluación: {total_test:,} secuencias}}}} \\\\\\\\\",\n",
    "    f\"\\\\multicolumn{{7}}{{l}}{{\\\\textbf{{Total utilizadas: {total_used:,} secuencias}}}} \\\\\\\\\",\n",
    "    \"\\\\hline\",\n",
    "    \"\\\\end{tabular}\",\n",
    "    \"\\\\end{table}\"\n",
    "])\n",
    "\n",
    "# Unir código LaTeX\n",
    "latex_content = '\\n'.join(latex_lines)\n",
    "\n",
    "# Guardar archivo\n",
    "filepath = os.path.join('latex_tables', 'dataset_distribution.tex')\n",
    "with open(filepath, 'w', encoding='utf-8') as f:\n",
    "    f.write(latex_content)\n",
    "\n",
    "# Imprimir solo el código LaTeX\n",
    "print(latex_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef58b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Distribución de secuencias por género bacteriano, origen y propósito (transpuesta)}\n",
      "\\label{tab:dataset_distribution_transposed}\n",
      "\\setlength{\\tabcolsep}{3pt}\n",
      "\\renewcommand{\\arraystretch}{1.2}\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{l|ccccccccccccccccccccccccccccc|c}\n",
      "\\hline\n",
      "\\rule{0pt}{3ex}\n",
      "\\textbf{Categoría} & \\rotatebox{90}{\\textbf{Acinetobacter}} & \\rotatebox{90}{\\textbf{Arthrobacter}} & \\rotatebox{90}{\\textbf{Bifidobacterium}} & \\rotatebox{90}{\\textbf{Bradyrhizobium}} & \\rotatebox{90}{\\textbf{Chryseobacterium}} & \\rotatebox{90}{\\textbf{Collinsella}} & \\rotatebox{90}{\\textbf{Corynebacterium}} & \\rotatebox{90}{\\textbf{Flavobacterium}} & \\rotatebox{90}{\\textbf{Mesorhizobium}} & \\rotatebox{90}{\\textbf{Methylobacterium}} & \\rotatebox{90}{\\textbf{Microbacterium}} & \\rotatebox{90}{\\textbf{Micromonospora}} & \\rotatebox{90}{\\textbf{Mycobacterium}} & \\rotatebox{90}{\\textbf{Nocardia}} & \\rotatebox{90}{\\textbf{Nocardioides}} & \\rotatebox{90}{\\textbf{Novosphingobium}} & \\rotatebox{90}{\\textbf{Paraburkholderia}} & \\rotatebox{90}{\\textbf{Paracoccus}} & \\rotatebox{90}{\\textbf{Pedobacter}} & \\rotatebox{90}{\\textbf{Pelagibacter}} & \\rotatebox{90}{\\textbf{Polynucleobacter}} & \\rotatebox{90}{\\textbf{Prevotella}} & \\rotatebox{90}{\\textbf{Prochlorococcus}} & \\rotatebox{90}{\\textbf{Pseudomonas}} & \\rotatebox{90}{\\textbf{Rhizobium}} & \\rotatebox{90}{\\textbf{Sphingomonas}} & \\rotatebox{90}{\\textbf{Streptococcus}} & \\rotatebox{90}{\\textbf{Streptomyces}} & \\rotatebox{90}{\\textbf{Vibrio}} & \\textbf{Total} \\\\\n",
      "\\hline\n",
      "\\rule{0pt}{2.5ex}\n",
      "\\textbf{Train GTDB} & 160 & 167 & 120 & 181 & 128 & 139 & 132 & 185 & 141 & 93 & 177 & 142 & 134 & 130 & 164 & 98 & 111 & 100 & 105 & 188 & 112 & 96 & 198 & 175 & 147 & 180 & 182 & 157 & 158 & \\textbf{4200} \\\\\n",
      "\\textbf{Train Entrez} & 40 & 33 & 80 & 19 & 72 & 61 & 68 & 15 & 59 & 107 & 23 & 58 & 66 & 70 & 36 & 102 & 89 & 100 & 95 & 12 & 88 & 104 & 2 & 25 & 53 & 20 & 18 & 43 & 42 & \\textbf{1600} \\\\\n",
      "\\textbf{Test GTDB} & 9 & 6 & 4 & 48 & 41 & 9 & 58 & 147 & -- & 4 & 103 & 1 & 236 & 1 & 2 & 2 & 4 & 2 & -- & 300 & 1 & -- & 46 & 300 & 2 & 42 & 253 & 261 & 16 & \\textbf{1898} \\\\\n",
      "\\textbf{Test Entrez} & 291 & 294 & 296 & 252 & 259 & 207 & 242 & 153 & 300 & 296 & 197 & 299 & 64 & 299 & 298 & 298 & 296 & 298 & 300 & -- & 299 & 300 & 193 & -- & 298 & 258 & 47 & 39 & 284 & \\textbf{6657} \\\\\n",
      "\\textbf{Leftover} & 564 & 625 & 543 & 683 & 558 & -- & 558 & 744 & 587 & 501 & 728 & 582 & 808 & 541 & 558 & 398 & 433 & 547 & 524 & 497 & 239 & 233 & -- & 1119 & 587 & 640 & 901 & 1355 & 502 & \\textbf{16555} \\\\\n",
      "\\textbf{Total} & 1064 & 1125 & 1043 & 1183 & 1058 & 416 & 1058 & 1244 & 1087 & 1001 & 1228 & 1082 & 1308 & 1041 & 1058 & 898 & 933 & 1047 & 1024 & 997 & 739 & 733 & 439 & 1619 & 1087 & 1140 & 1401 & 1855 & 1002 & \\textbf{30910} \\\\\n",
      "\\hline\n",
      "\\multicolumn{31}{l}{\\textbf{Géneros procesados: 29}} \\\\\n",
      "\\multicolumn{31}{l}{\\textbf{Total entrenamiento: 5,800 secuencias}} \\\\\n",
      "\\multicolumn{31}{l}{\\textbf{Total evaluación: 8,555 secuencias}} \\\\\n",
      "\\multicolumn{31}{l}{\\textbf{Total utilizadas: 14,355 secuencias}} \\\\\n",
      "\\hline\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('datos/datos_filtrados_sin_encoding.csv')\n",
    "\n",
    "# Crear directorio si no existe\n",
    "if not os.path.exists('latex_tables'):\n",
    "    os.makedirs('latex_tables')\n",
    "\n",
    "# Crear tabla de contingencia\n",
    "combined_data = []\n",
    "\n",
    "for genus in sorted(df['genus'].unique()):\n",
    "    genus_data = df[df['genus'] == genus]\n",
    "    \n",
    "    # Train por origen\n",
    "    train_gtdb = len(genus_data[(genus_data['purpose'] == 0) & (genus_data['origen'] == 'gtdb')])\n",
    "    train_entrez = len(genus_data[(genus_data['purpose'] == 0) & (genus_data['origen'] == 'entrez')])\n",
    "    \n",
    "    # Test por origen\n",
    "    test_gtdb = len(genus_data[(genus_data['purpose'] == 1) & (genus_data['origen'] == 'gtdb')])\n",
    "    test_entrez = len(genus_data[(genus_data['purpose'] == 1) & (genus_data['origen'] == 'entrez')])\n",
    "    \n",
    "    # Descartados\n",
    "    leftover = len(genus_data[genus_data['purpose'] == 2])\n",
    "    \n",
    "    # Total\n",
    "    total = len(genus_data)\n",
    "    \n",
    "    combined_data.append({\n",
    "        'genus': genus,\n",
    "        'train_gtdb': train_gtdb,\n",
    "        'train_entrez': train_entrez,\n",
    "        'test_gtdb': test_gtdb,\n",
    "        'test_entrez': test_entrez,\n",
    "        'leftover': leftover,\n",
    "        'total': total\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame\n",
    "table_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Obtener lista de géneros ordenados\n",
    "genera = sorted(df['genus'].unique())\n",
    "genera_escaped = [genus.replace('_', '\\\\_') for genus in genera]\n",
    "\n",
    "# Calcular totales por categoría\n",
    "totals = {\n",
    "    'train_gtdb': table_df['train_gtdb'].sum(),\n",
    "    'train_entrez': table_df['train_entrez'].sum(),\n",
    "    'test_gtdb': table_df['test_gtdb'].sum(),\n",
    "    'test_entrez': table_df['test_entrez'].sum(),\n",
    "    'leftover': table_df['leftover'].sum(),\n",
    "    'total': table_df['total'].sum()\n",
    "}\n",
    "\n",
    "# Generar código LaTeX transpuesto\n",
    "num_genera = len(genera)\n",
    "column_spec = 'l|' + 'c' * num_genera + '|c'\n",
    "\n",
    "latex_lines = [\n",
    "    \"\\\\begin{table}[htbp]\",\n",
    "    \"\\\\centering\",\n",
    "    \"\\\\caption{Distribución de secuencias por género bacteriano, origen y propósito (transpuesta)}\",\n",
    "    \"\\\\label{tab:dataset_distribution_transposed}\",\n",
    "    \"\\\\setlength{\\\\tabcolsep}{3pt}\",\n",
    "    \"\\\\renewcommand{\\\\arraystretch}{1.2}\",\n",
    "    \"\\\\resizebox{\\\\textwidth}{!}{%\",\n",
    "    f\"\\\\begin{{tabular}}{{{column_spec}}}\",\n",
    "    \"\\\\hline\",\n",
    "    \"\\\\rule{0pt}{3ex}\" # Espacio extra para acomodar texto rotado\n",
    "]\n",
    "\n",
    "# Encabezados de columnas (géneros rotados)\n",
    "header_line = \"\\\\textbf{Categoría} & \" + \" & \".join([f\"\\\\rotatebox{{90}}{{\\\\textbf{{{genus}}}}}\" for genus in genera_escaped]) + \" & \\\\textbf{Total} \\\\\\\\\"\n",
    "latex_lines.extend([\n",
    "    header_line,\n",
    "    \"\\\\hline\",\n",
    "    \"\\\\rule{0pt}{2.5ex}\" # Espacio después del header\n",
    "])\n",
    "\n",
    "# Crear diccionario para acceso rápido por género\n",
    "genus_data_dict = {row['genus']: row for _, row in table_df.iterrows()}\n",
    "\n",
    "# Categorías a mostrar\n",
    "categories = [\n",
    "    ('Train GTDB', 'train_gtdb'),\n",
    "    ('Train Entrez', 'train_entrez'),\n",
    "    ('Test GTDB', 'test_gtdb'),\n",
    "    ('Test Entrez', 'test_entrez'),\n",
    "    ('Leftover', 'leftover'),\n",
    "    ('Total', 'total')\n",
    "]\n",
    "\n",
    "# Agregar filas de datos\n",
    "for cat_name, cat_key in categories:\n",
    "    values = []\n",
    "    for genus in genera:\n",
    "        value = genus_data_dict[genus][cat_key]\n",
    "        values.append(str(value) if value > 0 else '--')\n",
    "    \n",
    "    total_value = totals[cat_key]\n",
    "    row_line = f\"\\\\textbf{{{cat_name}}} & \" + \" & \".join(values) + f\" & \\\\textbf{{{total_value}}} \\\\\\\\\"\n",
    "    latex_lines.append(row_line)\n",
    "\n",
    "# Calcular estadísticas para la tabla\n",
    "total_genera = len(table_df)\n",
    "total_train = totals['train_gtdb'] + totals['train_entrez']\n",
    "total_test = totals['test_gtdb'] + totals['test_entrez']\n",
    "total_used = total_train + total_test\n",
    "\n",
    "# Agregar estadísticas al final\n",
    "latex_lines.extend([\n",
    "    \"\\\\hline\",\n",
    "    f\"\\\\multicolumn{{{num_genera + 2}}}{{l}}{{\\\\textbf{{Géneros procesados: {total_genera}}}}} \\\\\\\\\",\n",
    "    f\"\\\\multicolumn{{{num_genera + 2}}}{{l}}{{\\\\textbf{{Total entrenamiento: {total_train:,} secuencias}}}} \\\\\\\\\",\n",
    "    f\"\\\\multicolumn{{{num_genera + 2}}}{{l}}{{\\\\textbf{{Total evaluación: {total_test:,} secuencias}}}} \\\\\\\\\",\n",
    "    f\"\\\\multicolumn{{{num_genera + 2}}}{{l}}{{\\\\textbf{{Total utilizadas: {total_used:,} secuencias}}}} \\\\\\\\\",\n",
    "    \"\\\\hline\",\n",
    "    \"\\\\end{tabular}%\",\n",
    "    \"}\",\n",
    "    \"\\\\end{table}\"\n",
    "])\n",
    "\n",
    "# Unir código LaTeX\n",
    "latex_content = '\\n'.join(latex_lines)\n",
    "\n",
    "# Guardar archivo\n",
    "filepath = os.path.join('latex_tables', 'dataset_distribution_transposed.tex')\n",
    "with open(filepath, 'w', encoding='utf-8') as f:\n",
    "    f.write(latex_content)\n",
    "\n",
    "# Imprimir solo el código LaTeX\n",
    "print(latex_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2661ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLA LATEX GENERADA:\n",
      "============================================================\n",
      "\\begin{table*}[htbp]\n",
      "\\centering\n",
      "\\caption{Estadísticas de Tiempo y Memoria por Encoding}\n",
      "\\label{tab:encoding_stats}\n",
      "\\scriptsize\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "& \\multicolumn{2}{c}{\\textbf{Tiempo (segundos)}} & \\textbf{Memoria} \\\\\n",
      "\\cmidrule(lr){2-3} \\cmidrule(lr){4-4}\n",
      "\\textbf{Encoding} & Promedio & Desv. Std & (MB) \\\\\n",
      "\\midrule\n",
      "PS\\_FFT & 2.01 & 0.01 & 188.69 \\\\\n",
      "PS\\_Wavelet & 2.48 & 0.01 & 378.29 \\\\\n",
      "PS\\_K-mers & 2.95 & 0.07 & 423.57 \\\\\n",
      "PS\\_One Hot & 4.33 & 0.01 & 1886.86 \\\\\n",
      "PS\\_K-mers + FFT & 4.34 & 0.04 & 188.45 \\\\\n",
      "PS\\_K-mers + Wavelet & 4.68 & 0.05 & 378.06 \\\\\n",
      "PS\\_One Hot + Wavelet & 5.64 & 0.01 & 1887.33 \\\\\n",
      "PS\\_One Hot + FFT & 5.86 & 0.01 & 943.33 \\\\\n",
      "AS\\_Wavelet & 9.78 & 0.06 & 1849.13 \\\\\n",
      "AS\\_FFT & 14.15 & 0.08 & 923.99 \\\\\n",
      "AS\\_K-mers & 14.17 & 0.34 & 1981.90 \\\\\n",
      "AS\\_One Hot & 20.17 & 0.41 & 9239.87 \\\\\n",
      "AS\\_K-mers + Wavelet & 20.35 & 0.21 & 1848.89 \\\\\n",
      "AS\\_One Hot + Wavelet & 24.44 & 0.12 & 9241.99 \\\\\n",
      "AS\\_K-mers + FFT & 25.25 & 0.24 & 923.75 \\\\\n",
      "AS\\_One Hot + FFT & 57.45 & 0.89 & 4619.83 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\\\[0.5em]\n",
      "\\footnotesize\n",
      "\\textit{Nota: Cada encoding fue ejecutado 50 veces para el análisis de tiempo. El uso de memoria es constante para cada encoding y no presenta varianza entre ejecuciones.}\n",
      "\\end{table*}\n",
      "============================================================\n",
      "\n",
      "DATOS ESTADÍSTICOS:\n",
      "            encoding  num_ejecuciones  tiempo_promedio_seg  tiempo_desv_std  tiempo_min  tiempo_max  memoria_promedio_mb  memoria_desv_std  memoria_min_mb  memoria_max_mb  eficiencia_mb_por_seg\n",
      "              PS_FFT               50                2.012            0.014       1.987       2.033               188.69               0.0          188.69          188.69                  93.79\n",
      "          PS_Wavelet               50                2.477            0.010       2.461       2.504               378.29               0.0          378.29          378.29                 152.70\n",
      "           PS_K-mers               50                2.947            0.071       2.873       3.075               423.57               0.0          423.57          423.57                 143.82\n",
      "          PS_One Hot               50                4.331            0.010       4.300       4.353              1886.86               0.0         1886.86         1886.86                 435.68\n",
      "     PS_K-mers + FFT               50                4.337            0.040       4.257       4.418               188.45               0.0          188.45          188.45                  43.45\n",
      " PS_K-mers + Wavelet               50                4.679            0.047       4.617       4.789               378.06               0.0          378.06          378.06                  80.81\n",
      "PS_One Hot + Wavelet               50                5.641            0.013       5.591       5.664              1887.33               0.0         1887.33         1887.33                 334.57\n",
      "    PS_One Hot + FFT               50                5.864            0.015       5.832       5.900               943.33               0.0          943.33          943.33                 160.86\n",
      "          AS_Wavelet               50                9.780            0.064       9.679       9.935              1849.13               0.0         1849.13         1849.13                 189.07\n",
      "              AS_FFT               50               14.154            0.078      13.929      14.259               923.99               0.0          923.99          923.99                  65.28\n",
      "           AS_K-mers               50               14.170            0.339      13.613      14.959              1981.90               0.0         1981.90         1981.90                 139.94\n",
      "          AS_One Hot               50               20.170            0.408      20.004      22.154              9239.87               0.0         9239.87         9239.87                 458.28\n",
      " AS_K-mers + Wavelet               50               20.346            0.207      20.161      21.657              1848.89               0.0         1848.89         1848.89                  90.88\n",
      "AS_One Hot + Wavelet               50               24.438            0.115      24.160      24.633              9241.99               0.0         9241.99         9241.99                 378.19\n",
      "     AS_K-mers + FFT               50               25.255            0.236      24.980      26.086               923.75               0.0          923.75          923.75                  36.58\n",
      "    AS_One Hot + FFT               50               57.449            0.892      56.157      58.967              4619.83               0.0         4619.83         4619.83                  80.44\n",
      "\n",
      "Tabla guardada en: latex_tables/tabla_encodings_tiempo_memoria.tex\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def generar_tabla_latex_encodings(archivo_csv):\n",
    "    \"\"\"\n",
    "    Genera una tabla LaTeX con estadísticas de tiempo y memoria para cada encoding.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer los datos\n",
    "    resultados = pd.read_csv(archivo_csv)\n",
    "    \n",
    "    # Ejecutar consulta SQL para obtener estadísticas\n",
    "    stats_df = duckdb.sql(\"\"\"\n",
    "    SELECT \n",
    "        encoding,\n",
    "        COUNT(*) as num_ejecuciones,\n",
    "        \n",
    "        -- Estadísticas de tiempo\n",
    "        ROUND(AVG(time), 3) as tiempo_promedio_seg,\n",
    "        ROUND(STDDEV(time), 3) as tiempo_desv_std,\n",
    "        ROUND(MIN(time), 3) as tiempo_min,\n",
    "        ROUND(MAX(time), 3) as tiempo_max,\n",
    "        \n",
    "        -- Estadísticas de memoria\n",
    "        ROUND(AVG(memory_used), 2) as memoria_promedio_mb,\n",
    "        ROUND(STDDEV(memory_used), 2) as memoria_desv_std,\n",
    "        ROUND(MIN(memory_used), 2) as memoria_min_mb,\n",
    "        ROUND(MAX(memory_used), 2) as memoria_max_mb,\n",
    "        \n",
    "        -- Eficiencia (memoria/tiempo)\n",
    "        ROUND(AVG(memory_used/time), 2) as eficiencia_mb_por_seg\n",
    "        \n",
    "    FROM resultados\n",
    "    GROUP BY encoding\n",
    "    ORDER BY tiempo_promedio_seg ASC;\n",
    "    \"\"\").to_df()\n",
    "    \n",
    "    # Obtener número total de iteraciones para la nota\n",
    "    total_iteraciones = resultados['iter'].nunique()\n",
    "    \n",
    "    # Generar tabla LaTeX\n",
    "    latex_code = \"\"\"\\\\begin{table*}[htbp]\n",
    "\\\\centering\n",
    "\\\\caption{Estadísticas de Tiempo y Memoria por Encoding}\n",
    "\\\\label{tab:encoding_stats}\n",
    "\\\\scriptsize\n",
    "\\\\begin{tabular}{lccc}\n",
    "\\\\toprule\n",
    "& \\\\multicolumn{2}{c}{\\\\textbf{Tiempo (segundos)}} & \\\\textbf{Memoria} \\\\\\\\\n",
    "\\\\cmidrule(lr){2-3} \\\\cmidrule(lr){4-4}\n",
    "\\\\textbf{Encoding} & Promedio & Desv. Std & (MB) \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    \n",
    "    # Agregar filas de datos\n",
    "    for _, row in stats_df.iterrows():\n",
    "        encoding = row['encoding'].replace('_', '\\\\_')  # Escapar guiones bajos para LaTeX\n",
    "        \n",
    "        latex_code += f\"{encoding} & \"\n",
    "        latex_code += f\"{row['tiempo_promedio_seg']:.2f} & \"\n",
    "        latex_code += f\"{row['tiempo_desv_std']:.2f} & \"\n",
    "        latex_code += f\"{row['memoria_promedio_mb']:.2f} \\\\\\\\\\n\"\n",
    "    \n",
    "    # Cerrar tabla\n",
    "    latex_code += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\"\"\"\n",
    "    \n",
    "    # Agregar nota sobre iteraciones\n",
    "    latex_code += f\"\"\"\\\\\\\\[0.5em]\n",
    "\\\\footnotesize\n",
    "\\\\textit{{Nota: Cada encoding fue ejecutado {total_iteraciones} veces para el análisis de tiempo. El uso de memoria es constante para cada encoding y no presenta varianza entre ejecuciones.}}\n",
    "\\\\end{{table*}}\"\"\"\n",
    "    \n",
    "    return latex_code, stats_df\n",
    "\n",
    "# Ejecutar función principal\n",
    "archivo_csv = \"datos/resultados_codificacion_tiempo_memoria.csv\"\n",
    "tabla_latex, df_estadisticas = generar_tabla_latex_encodings(archivo_csv)\n",
    "\n",
    "# Mostrar tabla LaTeX\n",
    "print(\"TABLA LATEX GENERADA:\")\n",
    "print(\"=\" * 60)\n",
    "print(tabla_latex)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Mostrar también los datos en formato DataFrame para verificación\n",
    "print(\"\\nDATOS ESTADÍSTICOS:\")\n",
    "print(df_estadisticas.to_string(index=False))\n",
    "\n",
    "# Crear directorio si no existe\n",
    "import os\n",
    "os.makedirs(\"latex_tables\", exist_ok=True)\n",
    "\n",
    "# Guardar en archivo\n",
    "with open(\"latex_tables/tabla_encodings_tiempo_memoria.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tabla_latex)\n",
    "\n",
    "print(f\"\\nTabla guardada en: latex_tables/tabla_encodings_tiempo_memoria.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387611e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLA LATEX GENERADA:\n",
      "============================================================\n",
      "\\begin{table*}[htbp]\n",
      "\\centering\n",
      "\\caption{Tiempos de Entrenamiento por Modelo y Encoding}\n",
      "\\label{tab:training_times}\n",
      "\\scriptsize\n",
      "\\begin{tabular}{llcc}\n",
      "\\toprule\n",
      "& & \\multicolumn{2}{c}{\\textbf{Tiempo (segundos)}} \\\\\n",
      "\\cmidrule(lr){3-4}\n",
      "\\textbf{Modelo} & \\textbf{Encoding} & Promedio & Desv. Std \\\\\n",
      "\\midrule\n",
      "RandomForest & AS\\_Wavelet & 1.74 & 0.00 \\\\\n",
      "RandomForest & AS\\_One Hot + Wavelet & 2.64 & 0.00 \\\\\n",
      "SVM & PS\\_K-mers + FFT & 2.94 & 0.01 \\\\\n",
      "SVM & PS\\_FFT & 3.22 & 0.01 \\\\\n",
      "RandomForest & PS\\_Wavelet & 4.50 & 0.02 \\\\\n",
      "RandomForest & AS\\_K-mers + Wavelet & 4.98 & 0.10 \\\\\n",
      "RandomForest & PS\\_K-mers & 5.28 & 0.11 \\\\\n",
      "RandomForest & AS\\_K-mers & 5.57 & 0.00 \\\\\n",
      "RandomForest & PS\\_One Hot + Wavelet & 5.66 & 0.04 \\\\\n",
      "RandomForest & PS\\_K-mers + Wavelet & 6.26 & 0.09 \\\\\n",
      "RandomForest & PS\\_One Hot & 6.28 & 0.03 \\\\\n",
      "RandomForest & AS\\_One Hot & 7.68 & 0.10 \\\\\n",
      "SVM & PS\\_Wavelet & 12.07 & 0.02 \\\\\n",
      "SVM & PS\\_K-mers + Wavelet & 13.60 & 0.41 \\\\\n",
      "RandomForest & PS\\_K-mers + FFT & 13.96 & 0.25 \\\\\n",
      "RandomForest & PS\\_FFT & 14.45 & 0.27 \\\\\n",
      "SVM & PS\\_One Hot + FFT & 20.25 & 0.06 \\\\\n",
      "SVM & PS\\_K-mers & 20.27 & 0.03 \\\\\n",
      "SVM & AS\\_K-mers + FFT & 21.69 & 0.06 \\\\\n",
      "SVM & AS\\_FFT & 23.92 & 0.07 \\\\\n",
      "RandomForest & AS\\_K-mers + FFT & 24.19 & 0.37 \\\\\n",
      "XGBoost & PS\\_FFT & 26.86 & 0.01 \\\\\n",
      "RandomForest & AS\\_FFT & 32.52 & 0.41 \\\\\n",
      "XGBoost & PS\\_K-mers + FFT & 33.13 & 0.03 \\\\\n",
      "RandomForest & PS\\_One Hot + FFT & 33.39 & 0.53 \\\\\n",
      "XGBoost & PS\\_Wavelet & 35.78 & 0.32 \\\\\n",
      "XGBoost & PS\\_K-mers + Wavelet & 42.47 & 0.39 \\\\\n",
      "SVM & AS\\_K-mers + Wavelet & 43.21 & 0.12 \\\\\n",
      "XGBoost & AS\\_Wavelet & 44.40 & 0.37 \\\\\n",
      "SVM & AS\\_K-mers & 45.82 & 0.20 \\\\\n",
      "RandomForest & AS\\_One Hot + FFT & 58.42 & 1.86 \\\\\n",
      "XGBoost & PS\\_K-mers & 60.38 & 0.05 \\\\\n",
      "SVM & AS\\_Wavelet & 68.46 & 0.10 \\\\\n",
      "XGBoost & PS\\_One Hot & 89.36 & 0.39 \\\\\n",
      "XGBoost & AS\\_K-mers & 90.95 & 0.43 \\\\\n",
      "SVM & PS\\_One Hot + Wavelet & 104.69 & 0.38 \\\\\n",
      "SVM & PS\\_One Hot & 106.63 & 0.22 \\\\\n",
      "XGBoost & PS\\_One Hot + Wavelet & 111.21 & 0.27 \\\\\n",
      "XGBoost & AS\\_K-mers + FFT & 125.59 & 0.02 \\\\\n",
      "XGBoost & AS\\_FFT & 130.90 & 0.32 \\\\\n",
      "XGBoost & AS\\_K-mers + Wavelet & 134.35 & 0.10 \\\\\n",
      "XGBoost & AS\\_One Hot & 150.86 & 0.70 \\\\\n",
      "XGBoost & PS\\_One Hot + FFT & 169.75 & 0.15 \\\\\n",
      "SVM & AS\\_One Hot + FFT & 190.65 & 1.13 \\\\\n",
      "XGBoost & AS\\_One Hot + Wavelet & 246.96 & 8.01 \\\\\n",
      "SVM & AS\\_One Hot + Wavelet & 431.53 & 1.02 \\\\\n",
      "SVM & AS\\_One Hot & 441.62 & 1.55 \\\\\n",
      "XGBoost & AS\\_One Hot + FFT & 864.05 & 1.23 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\\\[0.5em]\n",
      "\\footnotesize\n",
      "\\textit{Nota: Cada combinación modelo-encoding fue ejecutada 5 veces para el análisis de tiempos de entrenamiento.}\n",
      "\\end{table*}\n",
      "============================================================\n",
      "\n",
      "DATOS ESTADÍSTICOS:\n",
      "      modelo             encoding  num_ejecuciones  tiempo_promedio_seg  tiempo_desv_std  tiempo_min  tiempo_max\n",
      "RandomForest           AS_Wavelet                5                 1.74             0.00        1.74        1.75\n",
      "RandomForest AS_One Hot + Wavelet                5                 2.64             0.00        2.63        2.64\n",
      "         SVM      PS_K-mers + FFT                5                 2.94             0.01        2.92        2.95\n",
      "         SVM               PS_FFT                5                 3.22             0.01        3.20        3.23\n",
      "RandomForest           PS_Wavelet                5                 4.50             0.02        4.47        4.52\n",
      "RandomForest  AS_K-mers + Wavelet                5                 4.98             0.10        4.92        5.15\n",
      "RandomForest            PS_K-mers                5                 5.28             0.11        5.18        5.47\n",
      "RandomForest            AS_K-mers                5                 5.57             0.00        5.57        5.58\n",
      "RandomForest PS_One Hot + Wavelet                5                 5.66             0.04        5.59        5.69\n",
      "RandomForest  PS_K-mers + Wavelet                5                 6.26             0.09        6.18        6.40\n",
      "RandomForest           PS_One Hot                5                 6.28             0.03        6.23        6.30\n",
      "RandomForest           AS_One Hot                5                 7.68             0.10        7.61        7.85\n",
      "         SVM           PS_Wavelet                5                12.07             0.02       12.03       12.09\n",
      "         SVM  PS_K-mers + Wavelet                5                13.60             0.41       13.21       14.05\n",
      "RandomForest      PS_K-mers + FFT                5                13.96             0.25       13.68       14.29\n",
      "RandomForest               PS_FFT                5                14.45             0.27       14.31       14.92\n",
      "         SVM     PS_One Hot + FFT                5                20.25             0.06       20.15       20.31\n",
      "         SVM            PS_K-mers                5                20.27             0.03       20.24       20.31\n",
      "         SVM      AS_K-mers + FFT                5                21.69             0.06       21.59       21.74\n",
      "         SVM               AS_FFT                5                23.92             0.07       23.82       24.00\n",
      "RandomForest      AS_K-mers + FFT                5                24.19             0.37       23.92       24.81\n",
      "     XGBoost               PS_FFT                5                26.86             0.01       26.85       26.88\n",
      "RandomForest               AS_FFT                5                32.52             0.41       32.17       33.19\n",
      "     XGBoost      PS_K-mers + FFT                5                33.13             0.03       33.10       33.17\n",
      "RandomForest     PS_One Hot + FFT                5                33.39             0.53       33.03       34.30\n",
      "     XGBoost           PS_Wavelet                5                35.78             0.32       35.59       36.35\n",
      "     XGBoost  PS_K-mers + Wavelet                5                42.47             0.39       42.22       43.15\n",
      "         SVM  AS_K-mers + Wavelet                5                43.21             0.12       43.01       43.34\n",
      "     XGBoost           AS_Wavelet                5                44.40             0.37       44.17       45.04\n",
      "         SVM            AS_K-mers                5                45.82             0.20       45.58       46.11\n",
      "RandomForest     AS_One Hot + FFT                5                58.42             1.86       56.85       60.57\n",
      "     XGBoost            PS_K-mers                5                60.38             0.05       60.33       60.44\n",
      "         SVM           AS_Wavelet                5                68.46             0.10       68.28       68.53\n",
      "     XGBoost           PS_One Hot                5                89.36             0.39       89.09       90.05\n",
      "     XGBoost            AS_K-mers                5                90.95             0.43       90.26       91.40\n",
      "         SVM PS_One Hot + Wavelet                5               104.69             0.38      104.33      105.30\n",
      "         SVM           PS_One Hot                5               106.63             0.22      106.25      106.81\n",
      "     XGBoost PS_One Hot + Wavelet                5               111.21             0.27      110.95      111.48\n",
      "     XGBoost      AS_K-mers + FFT                5               125.59             0.02      125.56      125.62\n",
      "     XGBoost               AS_FFT                5               130.90             0.32      130.34      131.12\n",
      "     XGBoost  AS_K-mers + Wavelet                5               134.35             0.10      134.24      134.46\n",
      "     XGBoost           AS_One Hot                5               150.86             0.70      150.22      151.75\n",
      "     XGBoost     PS_One Hot + FFT                5               169.75             0.15      169.62      169.98\n",
      "         SVM     AS_One Hot + FFT                5               190.65             1.13      189.41      191.69\n",
      "     XGBoost AS_One Hot + Wavelet                5               246.96             8.01      232.79      251.54\n",
      "         SVM AS_One Hot + Wavelet                5               431.53             1.02      430.09      432.56\n",
      "         SVM           AS_One Hot                5               441.62             1.55      439.60      443.28\n",
      "     XGBoost     AS_One Hot + FFT                5               864.05             1.23      862.11      865.06\n",
      "\n",
      "Tabla guardada en: latex_tables/tabla_tiempos_entrenamiento.tex\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Leer los datos\n",
    "resultados = pd.read_csv(\"results/training_times/training_times_complete_detailed.csv\")\n",
    "\n",
    "# Ejecutar consulta SQL para obtener estadísticas\n",
    "stats_df = duckdb.sql(\"\"\"\n",
    "SELECT \n",
    "    modelo,\n",
    "    encoding,\n",
    "    COUNT(*) as num_ejecuciones,\n",
    "    ROUND(AVG(tiempo), 2) as tiempo_promedio_seg,\n",
    "    ROUND(STDDEV(tiempo), 2) as tiempo_desv_std,\n",
    "    ROUND(MIN(tiempo), 2) as tiempo_min,\n",
    "    ROUND(MAX(tiempo), 2) as tiempo_max\n",
    "FROM resultados\n",
    "GROUP BY modelo, encoding\n",
    "-- ORDER BY modelo ASC, tiempo_promedio_seg ASC;\n",
    "ORDER BY tiempo_promedio_seg ASC;\n",
    "\"\"\").to_df()\n",
    "\n",
    "# Obtener número total de iteraciones para la nota\n",
    "total_iteraciones = resultados['iter'].nunique()\n",
    "\n",
    "# Generar tabla LaTeX\n",
    "latex_code = \"\"\"\\\\begin{table*}[htbp]\n",
    "\\\\centering\n",
    "\\\\caption{Tiempos de Entrenamiento por Modelo y Encoding}\n",
    "\\\\label{tab:training_times}\n",
    "\\\\scriptsize\n",
    "\\\\begin{tabular}{llcc}\n",
    "\\\\toprule\n",
    "& & \\\\multicolumn{2}{c}{\\\\textbf{Tiempo (segundos)}} \\\\\\\\\n",
    "\\\\cmidrule(lr){3-4}\n",
    "\\\\textbf{Modelo} & \\\\textbf{Encoding} & Promedio & Desv. Std \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Agregar filas de datos\n",
    "for _, row in stats_df.iterrows():\n",
    "    modelo = row['modelo']\n",
    "    encoding = row['encoding'].replace('_', '\\\\_')  # Escapar guiones bajos para LaTeX\n",
    "    \n",
    "    latex_code += f\"{modelo} & {encoding} & \"\n",
    "    latex_code += f\"{row['tiempo_promedio_seg']:.2f} & \"\n",
    "    latex_code += f\"{row['tiempo_desv_std']:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "# Cerrar tabla\n",
    "latex_code += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\"\"\"\n",
    "\n",
    "# Agregar nota sobre iteraciones\n",
    "latex_code += f\"\"\"\\\\\\\\[0.5em]\n",
    "\\\\footnotesize\n",
    "\\\\textit{{Nota: Cada combinación modelo-encoding fue ejecutada {total_iteraciones} veces para el análisis de tiempos de entrenamiento.}}\n",
    "\\\\end{{table*}}\"\"\"\n",
    "\n",
    "# Mostrar tabla LaTeX\n",
    "print(\"TABLA LATEX GENERADA:\")\n",
    "print(\"=\" * 60)\n",
    "print(latex_code)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Mostrar también los datos en formato DataFrame para verificación\n",
    "print(\"\\nDATOS ESTADÍSTICOS:\")\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs(\"latex_tables\", exist_ok=True)\n",
    "\n",
    "# Guardar en archivo\n",
    "with open(\"latex_tables/tabla_tiempos_entrenamiento.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_code)\n",
    "\n",
    "print(f\"\\nTabla guardada en: latex_tables/tabla_tiempos_entrenamiento.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
