{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_taxonomy(description):\n",
    "    \"\"\"Extrae información taxonómica de la descripción\"\"\"\n",
    "    tax_match = re.search(r'd([^;]+);p([^;]+);c([^;]+);o([^;]+);f([^;]+);g([^;]+);s__([^\\s]+)', description)\n",
    "    if tax_match:\n",
    "        return {\n",
    "            'domain': tax_match.group(1),\n",
    "            'phylum': tax_match.group(2),\n",
    "            'class': tax_match.group(3),\n",
    "            'order': tax_match.group(4),\n",
    "            'family': tax_match.group(5),\n",
    "            'genus': tax_match.group(6),\n",
    "            'species': tax_match.group(7)\n",
    "        }\n",
    "    return dict.fromkeys(['domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'])\n",
    "\n",
    "def fna_to_dataframe(fna_file):\n",
    "    \"\"\"Convierte archivo FNA a DataFrame\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for record in SeqIO.parse(fna_file, \"fasta\"):\n",
    "        sequence = str(record.seq)\n",
    "        tax_info = parse_taxonomy(record.description)\n",
    "        \n",
    "        records.append({\n",
    "            'sequence_id': record.id,\n",
    "            'sequence': sequence,\n",
    "            'sequence_length': len(sequence),\n",
    "            'gc_content': (sequence.count(\"G\") + sequence.count(\"C\")) / len(sequence) * 100,\n",
    "            'domain': tax_info['domain'],\n",
    "            'phylum': tax_info['phylum'],\n",
    "            'class': tax_info['class'],\n",
    "            'order': tax_info['order'],\n",
    "            'family': tax_info['family'],\n",
    "            'genus': tax_info['genus'],\n",
    "            'species': tax_info['species']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def export_to_fasta(df, output_file):\n",
    "    \"\"\"Exporta DataFrame a archivo FASTA con información seleccionada\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            header = f\">{row['sequence_id']} length={row['sequence_length']} GC={row['gc_content']} genus={row['genus']}\"\n",
    "            f.write(f\"{header}\\n{row['sequence']}\\n\")\n",
    "\n",
    "def read_exported_fasta(fasta_file):\n",
    "    \"\"\"Lee el archivo FASTA exportado\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        header_info = record.description.split()\n",
    "        \n",
    "        # Extraer información del header\n",
    "        sequence_id = header_info[0]\n",
    "        length = int(header_info[1].split('=')[1])\n",
    "        gc = float(header_info[2].split('=')[1])\n",
    "        genus = header_info[3].split('=')[1]\n",
    "        \n",
    "        records.append({\n",
    "            'sequence_id': sequence_id,\n",
    "            'sequence': str(record.seq),\n",
    "            'sequence_length': length,\n",
    "            'gc_content': gc,\n",
    "            'genus': genus\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fna_to_dataframe('datos/datos_originales_ncbi.fna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain: 1\n",
      "phylum: 171\n",
      "class: 458\n",
      "order: 1553\n",
      "family: 3884\n",
      "genus: 16117\n",
      "species: 16117\n"
     ]
    }
   ],
   "source": [
    "columnas=[\"domain\",'phylum','class','order','family','genus','species']\n",
    "\n",
    "for c in columnas:\n",
    "    print(f\"{c}: {df[c].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limpiar_col=['domain', 'phylum', 'class', 'order', 'family', 'genus']\n",
    "\n",
    "for c in limpiar_col:\n",
    "    for i,v in enumerate(df[c]):\n",
    "        df.loc[i,c]=v.replace('__', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=duckdb.sql(\"\"\"\n",
    "select * from df\n",
    "           where sequence_length<1600 and sequence_length>1300\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>domain: 1\n",
      ">>>phylum: 155\n",
      ">>>class: 385\n",
      ">>>order: 1227\n",
      ">>>family: 2858\n",
      ">>>genus: 10576\n",
      ">>>species: 10576\n"
     ]
    }
   ],
   "source": [
    "columnas=[\"domain\",'phylum','class','order','family','genus','species']\n",
    "\n",
    "for c in columnas:\n",
    "    print(f\">>>{c}: {df[c].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_sequence_length_enhanced(df, col, color_scheme='Viridis', \n",
    "#                                  show_stats=True, show_cumulative=False,\n",
    "#                                  bin_size=None, text_size_factor=1.3):\n",
    "#     \"\"\"\n",
    "#     Enhanced function to visualize DNA sequence length distribution\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: DataFrame containing the data\n",
    "#     - col: Column name with sequence lengths\n",
    "#     - color_scheme: Color scheme for the chart ('Viridis', 'Plasma', 'Turbo', etc.)\n",
    "#     - show_stats: Show descriptive statistics\n",
    "#     - show_cumulative: Show cumulative distribution\n",
    "#     - bin_size: Bin size (for very large sequences)\n",
    "#     - text_size_factor: Factor to increase all text sizes\n",
    "#     \"\"\"\n",
    "#     # Extract length data\n",
    "#     sequence_lengths = df[col].copy()\n",
    "    \n",
    "#     # Calculate statistics\n",
    "#     stats = {\n",
    "#         'Mean': np.mean(sequence_lengths),\n",
    "#         'Median': np.median(sequence_lengths),\n",
    "#         'Mode': sequence_lengths.mode().iloc[0] if not sequence_lengths.mode().empty else None,\n",
    "#         'Min': sequence_lengths.min(),\n",
    "#         'Max': sequence_lengths.max(),\n",
    "#         'Std. Dev': np.std(sequence_lengths)\n",
    "#     }\n",
    "    \n",
    "#     # Determine if we should use bins for widely dispersed distributions\n",
    "#     unique_lengths = len(sequence_lengths.unique())\n",
    "#     use_histogram = unique_lengths > 50 or (stats['Max'] - stats['Min']) > 100\n",
    "    \n",
    "#     if bin_size is None:\n",
    "#         # Calculate bin_size automatically to show more columns\n",
    "#         # We want at least 30 bins for a more detailed histogram\n",
    "#         range_length = stats['Max'] - stats['Min']\n",
    "#         bin_size = max(1, int(range_length / 40))  # Ensure at least 40 bins for detailed view\n",
    "    \n",
    "#     # Create base figure\n",
    "#     fig = go.Figure()\n",
    "    \n",
    "#     # Count sequence length frequencies\n",
    "#     sequence_counts = df[col].value_counts().reset_index()\n",
    "#     sequence_counts.columns = ['Length', 'Frequency']\n",
    "#     sequence_counts = sequence_counts.sort_values('Length')\n",
    "    \n",
    "#     # Calculate cumulative distribution\n",
    "#     total = sequence_counts['Frequency'].sum()\n",
    "#     sequence_counts['Percentage'] = sequence_counts['Frequency'] * 100 / total\n",
    "#     sequence_counts['Cumulative'] = sequence_counts['Frequency'].cumsum() * 100 / total\n",
    "    \n",
    "#     # Add bar chart with larger bars and no colorbar\n",
    "#     fig.add_trace(go.Bar(\n",
    "#         x=sequence_counts['Length'],\n",
    "#         y=sequence_counts['Frequency'],\n",
    "#         name='Frequency',\n",
    "#         marker=dict(\n",
    "#             color=sequence_counts['Frequency'],\n",
    "#             colorscale=color_scheme,\n",
    "#             showscale=False,  # Remove the colorbar\n",
    "#         ),\n",
    "#         hovertemplate='Length: %{x}<br>Frequency: %{y}<br>Percentage: %{text:.2f}%<extra></extra>',\n",
    "#         text=sequence_counts['Percentage']\n",
    "#     ))\n",
    "    \n",
    "#     # Add cumulative distribution line\n",
    "#     if show_cumulative:\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=sequence_counts['Length'],\n",
    "#             y=sequence_counts['Cumulative'],\n",
    "#             mode='lines+markers',\n",
    "#             name='% Cumulative',\n",
    "#             line=dict(color='rgba(219, 64, 82, 0.8)', width=3),\n",
    "#             marker=dict(size=8),\n",
    "#             yaxis='y2',\n",
    "#             hovertemplate='Length: %{x}<br>Cumulative: %{y:.2f}%<extra></extra>'\n",
    "#         ))\n",
    "    \n",
    "#     # Add reference lines for important statistics\n",
    "#     if show_stats:\n",
    "#         # Add vertical line for mean\n",
    "#         fig.add_vline(x=stats['Mean'], line_width=2, line_dash=\"dash\", line_color=\"green\",\n",
    "#                      annotation=dict(\n",
    "#                          text=f\"Mean: {stats['Mean']:.2f}\",\n",
    "#                          font=dict(size=14 * text_size_factor, color=\"green\"),\n",
    "#                          xanchor=\"right\",\n",
    "#                          yanchor=\"top\"\n",
    "#                      ))\n",
    "        \n",
    "#         # Add vertical line for median\n",
    "#         fig.add_vline(x=stats['Median'], line_width=2, line_dash=\"dash\", line_color=\"red\",\n",
    "#                      annotation=dict(\n",
    "#                          text=f\"Median: {stats['Median']}\",\n",
    "#                          font=dict(size=14 * text_size_factor, color=\"red\"),\n",
    "#                          xanchor=\"left\",\n",
    "#                          yanchor=\"top\"\n",
    "#                      ))\n",
    "    \n",
    "#     # Create statistics text block with larger font\n",
    "#     stats_text = \"<br>\".join([\n",
    "#         f\"<b style='font-size:{14 * text_size_factor}px'>Descriptive Statistics:</b>\",\n",
    "#         f\"<span style='font-size:{13 * text_size_factor}px'>Mean: {stats['Mean']:.2f}</span>\",\n",
    "#         f\"<span style='font-size:{13 * text_size_factor}px'>Median: {stats['Median']}</span>\",\n",
    "#         f\"<span style='font-size:{13 * text_size_factor}px'>Mode: {stats['Mode']}</span>\",\n",
    "#         f\"<span style='font-size:{13 * text_size_factor}px'>Min: {stats['Min']}, Max: {stats['Max']}</span>\",\n",
    "#         f\"<span style='font-size:{13 * text_size_factor}px'>Std. Dev: {stats['Std. Dev']:.2f}</span>\",\n",
    "#         f\"<span style='font-size:{13 * text_size_factor}px'>Total sequences: {len(sequence_lengths)}</span>\"\n",
    "#     ])\n",
    "    \n",
    "#     # Customize the layout with larger fonts\n",
    "#     fig.update_layout(\n",
    "#         title={\n",
    "#             'text': 'DNA Sequence Length Distribution',\n",
    "#             'y':0.95,\n",
    "#             'x':0.5,\n",
    "#             'xanchor': 'center',\n",
    "#             'yanchor': 'top',\n",
    "#             'font': dict(size=24 * text_size_factor, color='black')\n",
    "#         },\n",
    "#         xaxis_title={\n",
    "#             'text': 'Sequence Length (bp)',\n",
    "#             'font': dict(size=18 * text_size_factor)\n",
    "#         },\n",
    "#         yaxis_title={\n",
    "#             'text': 'Number of Sequences',\n",
    "#             'font': dict(size=18 * text_size_factor)\n",
    "#         },\n",
    "#         template='plotly_white',\n",
    "#         legend=dict(\n",
    "#             orientation=\"h\",\n",
    "#             yanchor=\"bottom\",\n",
    "#             y=1.02,\n",
    "#             xanchor=\"right\",\n",
    "#             x=1,\n",
    "#             font=dict(size=14 * text_size_factor)\n",
    "#         ),\n",
    "#         margin=dict(l=80, r=80, t=120, b=80),\n",
    "#         annotations=[\n",
    "#             dict(\n",
    "#                 xref='paper',\n",
    "#                 yref='paper',\n",
    "#                 x=0.99,\n",
    "#                 y=0.99,\n",
    "#                 showarrow=False,\n",
    "#                 text=stats_text,\n",
    "#                 align='right',\n",
    "#                 xanchor='right',\n",
    "#                 yanchor='top',\n",
    "#                 bgcolor='rgba(255, 255, 255, 0.8)',\n",
    "#                 bordercolor='grey',\n",
    "#                 borderwidth=1\n",
    "#             )\n",
    "#         ],\n",
    "#         width=1600, \n",
    "#         height=900,\n",
    "#         font=dict(size=14 * text_size_factor)  # Global font size increase\n",
    "#     )\n",
    "    \n",
    "#     # Configure secondary Y-axis for cumulative distribution\n",
    "#     if show_cumulative:\n",
    "#         fig.update_layout(\n",
    "#             yaxis2=dict(\n",
    "#                 title={\n",
    "#                     'text': 'Cumulative Percentage (%)',\n",
    "#                     'font': dict(size=18 * text_size_factor, color='rgba(219, 64, 82, 0.8)')\n",
    "#                 },\n",
    "#                 tickfont=dict(color='rgba(219, 64, 82, 0.8)', size=14 * text_size_factor),\n",
    "#                 overlaying='y',\n",
    "#                 side='right',\n",
    "#                 range=[0, 100]\n",
    "#             )\n",
    "#         )\n",
    "    \n",
    "#     # Increase tick font size for better readability\n",
    "#     fig.update_xaxes(tickfont=dict(size=14 * text_size_factor))\n",
    "#     fig.update_yaxes(tickfont=dict(size=14 * text_size_factor))\n",
    "    \n",
    "#     # Show and save graph\n",
    "#     fig.show()\n",
    "    \n",
    "#     # Save as PNG and HTML for flexibility\n",
    "#     # fig.write_image('distribucion_sin_filtrar.png', scale=5, width=1600, height=900)\n",
    "#     # fig.write_image('bact_distribution_enhanced.png', scale=5, width=1600, height=900)\n",
    "#     # fig.write_html('bact_distribution_interactive.html', include_plotlyjs='cdn')\n",
    "    \n",
    "#     # return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sequence_length_enhanced(df, 'sequence_length', \n",
    "#                              color_scheme='Viridis',\n",
    "#                              show_stats=True, \n",
    "#                              show_cumulative=False,\n",
    "#                              text_size_factor=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sequence_length_enhanced(dfcopia, 'sequence_length', \n",
    "#                              color_scheme='Viridis',\n",
    "#                              show_stats=True, \n",
    "#                              show_cumulative=False,\n",
    "#                              text_size_factor=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Limpieza de las secuencias que no tengan los nucleótidos ACGT\n",
    "base=set('ACGT')\n",
    "drop_idx=[]\n",
    "for i,j in enumerate(df['sequence']):\n",
    "    if set(j)!=base:\n",
    "        drop_idx.append(i)\n",
    "print(len(drop_idx))\n",
    "df=df.drop(drop_idx)\n",
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hizo para explorar los datos y conteo de datos por género\n",
    "conteo={'genus':[],'conteo':[]}\n",
    "for i in df['genus'].unique():\n",
    "    conteo['genus'].append(i)\n",
    "    conteo['conteo'].append(len(df[df['genus']==i]))\n",
    "\n",
    "df_conteo=pd.DataFrame(conteo)\n",
    "\n",
    "temp=df_conteo['conteo']>=100\n",
    "df_conteo=df_conteo.loc[temp]\n",
    "df_conteo=df_conteo.reset_index(drop=True)\n",
    "\n",
    "genes=df_conteo['genus'].tolist()\n",
    "\n",
    "# Filtro para los géneros que tienen más de 100 representantes\n",
    "# Se separa en datos de entrenamiento (80-120 secuencias) y evaluación (resto)\n",
    "templist_train = []\n",
    "templist_eval = []\n",
    "\n",
    "for i in genes:\n",
    "    temp = df[df['genus']==i]\n",
    "    temp = temp.sort_values('sequence_length', ascending=False)\n",
    "    \n",
    "    # Determinar cuántas secuencias usar para entrenamiento\n",
    "    total_sequences = len(temp)\n",
    "    \n",
    "    if total_sequences >= 120:\n",
    "        # Si tiene 120 o más, tomar 120 para entrenamiento\n",
    "        train_size = 120\n",
    "    elif total_sequences >= 80:\n",
    "        # Si tiene entre 80-119, tomar todas para entrenamiento\n",
    "        train_size = total_sequences\n",
    "    else:\n",
    "        # Si tiene menos de 80, tomar todas para entrenamiento (aunque sean pocas)\n",
    "        train_size = total_sequences\n",
    "    \n",
    "    # Separar en entrenamiento y evaluación\n",
    "    temp_train = temp.iloc[:train_size].copy()\n",
    "    temp_eval = temp.iloc[train_size:].copy()\n",
    "    \n",
    "    # Marcar como datos de entrenamiento\n",
    "    temp_train['is_training'] = True\n",
    "    \n",
    "    # Marcar como datos de evaluación (si existen)\n",
    "    if len(temp_eval) > 0:\n",
    "        temp_eval['is_training'] = False\n",
    "        templist_eval.append(temp_eval)\n",
    "    \n",
    "    templist_train.append(temp_train)\n",
    "    \n",
    "    # print(f\"{i}: Total={total_sequences}, Entrenamiento={len(temp_train)}, Evaluación={len(temp_eval)}\")\n",
    "\n",
    "# Concatenar todos los datos\n",
    "df_train = pd.concat(templist_train)\n",
    "if templist_eval:  # Solo si hay datos de evaluación\n",
    "    df_eval = pd.concat(templist_eval)\n",
    "    df_final = pd.concat([df_train, df_eval])\n",
    "else:\n",
    "    df_final = df_train\n",
    "\n",
    "df_final = df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se exportan los datos filtrados del df hacia un archivo fasta para utilizar \n",
    "# el programa MAFFT para el alineamiento de las secuencias\n",
    "export_to_fasta(df_final, \"datos/fasta_final.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del archivo generado por el programa MFFT\n",
    "# mafft --auto --thread 12 --maxiterate 1000 --localpair fasta_final.fasta > fasta_final_alineado.fasta\n",
    "df_imported = read_exported_fasta(\"datos/fasta_final_alineado.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=duckdb.sql(\"\"\"\n",
    "select * from df_imported d\n",
    "join df_final on d.sequence_id= df_final.sequence_id\n",
    "\"\"\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_final[['sequence_id', 'sequence', 'sequence_1',  'sequence_length', 'domain', 'phylum', 'class', 'order', 'family','genus', 'species', 'is_training']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_final.rename(columns={\n",
    "    \"sequence_1\":'original_sequence'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplazan los gaps generados por el alineamiento por la letra N\n",
    "df_final['sequence']=[i.replace('-','N').upper() for i in df_final['sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado del archivo ya procesado y listo para los modelos\n",
    "df_final.to_csv('datos/datos_filtrados_sin_encoding.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
