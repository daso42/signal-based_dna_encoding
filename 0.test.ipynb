{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d82cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22, 111, 55, 29]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def generate_kmers_dict(k, unique_chars=set('ACGNT')):\n",
    "    kmers = product(unique_chars, repeat=k)\n",
    "    kmer_dict = {''.join(kmer): i for i,kmer in enumerate(kmers)}\n",
    "    return kmer_dict\n",
    "\n",
    "def k_mers(sequencias, k=3, unique_chars=set('ACGNT')):\n",
    "    kmers_map=generate_kmers_dict(k, unique_chars)\n",
    "    templist=[]\n",
    "    for seq in sequencias:\n",
    "        temp=[seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "        templist.append([kmers_map[i] for i in temp])\n",
    "    return templist\n",
    "\n",
    "k_mers(['ACGTAC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e240f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30910"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "# os.listdir(\"results/gridsearch_results/\")\n",
    "len(pd.read_csv('datos/datos_filtrados_sin_encoding.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d721ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = os.listdir(\"results/gridsearch_results/\")\n",
    "all_data = []\n",
    "\n",
    "for file_path in json_files:\n",
    "    with open(f\"results/gridsearch_results/{file_path}\", 'r') as f:\n",
    "        # print(file_path)\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3b14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df={\n",
    "    'modelo':[],\n",
    "    'encoding':[],\n",
    "    'best_params':[]\n",
    "}\n",
    "\n",
    "for j in all_data:\n",
    "    df['modelo'].append(j['algorithm'])\n",
    "    df['encoding'].append(j['encoding'])\n",
    "    df['best_params'].append(j['best_params'])\n",
    "\n",
    "df=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee132b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"RandomForest\": {\n",
      "        \"AS_FFT\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 10,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"AS_K-mers + FFT\": {\n",
      "            \"max_depth\": 10,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"AS_K-mers + Wavelet\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 10,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"AS_K-mers\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"AS_One Hot + FFT\": {\n",
      "            \"max_depth\": 10,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"AS_One Hot + Wavelet\": {\n",
      "            \"max_depth\": null,\n",
      "            \"min_samples_split\": 10,\n",
      "            \"n_estimators\": 50\n",
      "        },\n",
      "        \"AS_One Hot\": {\n",
      "            \"max_depth\": 10,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"AS_Wavelet\": {\n",
      "            \"max_depth\": null,\n",
      "            \"min_samples_split\": 5,\n",
      "            \"n_estimators\": 50\n",
      "        },\n",
      "        \"PS_FFT\": {\n",
      "            \"max_depth\": null,\n",
      "            \"min_samples_split\": 5,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_K-mers + FFT\": {\n",
      "            \"max_depth\": null,\n",
      "            \"min_samples_split\": 10,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_K-mers + Wavelet\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_K-mers\": {\n",
      "            \"max_depth\": null,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_One Hot + FFT\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 5,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_One Hot + Wavelet\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 2,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_One Hot\": {\n",
      "            \"max_depth\": 20,\n",
      "            \"min_samples_split\": 5,\n",
      "            \"n_estimators\": 200\n",
      "        },\n",
      "        \"PS_Wavelet\": {\n",
      "            \"max_depth\": 30,\n",
      "            \"min_samples_split\": 5,\n",
      "            \"n_estimators\": 200\n",
      "        }\n",
      "    },\n",
      "    \"SVM\": {\n",
      "        \"AS_FFT\": {\n",
      "            \"C\": 10,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_K-mers + FFT\": {\n",
      "            \"C\": 1,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_K-mers + Wavelet\": {\n",
      "            \"C\": 100,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_K-mers\": {\n",
      "            \"C\": 10,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_One Hot + FFT\": {\n",
      "            \"C\": 10,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_One Hot + Wavelet\": {\n",
      "            \"C\": 100,\n",
      "            \"gamma\": \"auto\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_One Hot\": {\n",
      "            \"C\": 10,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"AS_Wavelet\": {\n",
      "            \"C\": 100,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"PS_FFT\": {\n",
      "            \"C\": 0.1,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"linear\"\n",
      "        },\n",
      "        \"PS_K-mers + FFT\": {\n",
      "            \"C\": 0.1,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"linear\"\n",
      "        },\n",
      "        \"PS_K-mers + Wavelet\": {\n",
      "            \"C\": 100,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"PS_K-mers\": {\n",
      "            \"C\": 10,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"PS_One Hot + FFT\": {\n",
      "            \"C\": 0.1,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"linear\"\n",
      "        },\n",
      "        \"PS_One Hot + Wavelet\": {\n",
      "            \"C\": 100,\n",
      "            \"gamma\": \"auto\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"PS_One Hot\": {\n",
      "            \"C\": 100,\n",
      "            \"gamma\": \"auto\",\n",
      "            \"kernel\": \"rbf\"\n",
      "        },\n",
      "        \"PS_Wavelet\": {\n",
      "            \"C\": 0.1,\n",
      "            \"gamma\": \"scale\",\n",
      "            \"kernel\": \"linear\"\n",
      "        }\n",
      "    },\n",
      "    \"XGBoost\": {\n",
      "        \"AS_FFT\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"AS_K-mers + FFT\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.8\n",
      "        },\n",
      "        \"AS_K-mers + Wavelet\": {\n",
      "            \"colsample_bytree\": 0.8,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 50,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"AS_K-mers\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"AS_One Hot + FFT\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.8\n",
      "        },\n",
      "        \"AS_One Hot + Wavelet\": {\n",
      "            \"colsample_bytree\": 0.9,\n",
      "            \"learning_rate\": 0.3,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 50,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"AS_One Hot\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 50,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"AS_Wavelet\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 50,\n",
      "            \"subsample\": 0.8\n",
      "        },\n",
      "        \"PS_FFT\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.8\n",
      "        },\n",
      "        \"PS_K-mers + FFT\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"PS_K-mers + Wavelet\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 3,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.8\n",
      "        },\n",
      "        \"PS_K-mers\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"PS_One Hot + FFT\": {\n",
      "            \"colsample_bytree\": 0.8,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"PS_One Hot + Wavelet\": {\n",
      "            \"colsample_bytree\": 0.9,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"PS_One Hot\": {\n",
      "            \"colsample_bytree\": 0.7,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.7\n",
      "        },\n",
      "        \"PS_Wavelet\": {\n",
      "            \"colsample_bytree\": 0.9,\n",
      "            \"learning_rate\": 0.1,\n",
      "            \"max_depth\": 6,\n",
      "            \"n_estimators\": 100,\n",
      "            \"subsample\": 0.9\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parametros_optimos = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    modelo = row['modelo']\n",
    "    encoding = row['encoding']\n",
    "    params = row['best_params']\n",
    "    \n",
    "    if modelo not in parametros_optimos:\n",
    "        parametros_optimos[modelo] = {}\n",
    "    \n",
    "    parametros_optimos[modelo][encoding] = params\n",
    "\n",
    "print(json.dumps(parametros_optimos, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142020e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "def generate_kmers_dict(k, unique_chars=set('ACGNT')):\n",
    "    kmers = product(unique_chars, repeat=k)\n",
    "    kmer_dict = {''.join(kmer): i for i,kmer in enumerate(kmers)}\n",
    "    return kmer_dict\n",
    "\n",
    "df=generate_kmers_dict(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5bc8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_mers(sequencias, k=3, unique_chars=set('ACGNT')):\n",
    "    kmers_map=generate_kmers_dict(k, unique_chars)\n",
    "    templist=[]\n",
    "    for seq in sequencias:\n",
    "        temp=[seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "        templist.append([kmers_map[i] for i in temp])\n",
    "    return templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6421f72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[102, 13, 66, 84, 45, 102]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_mers(['ACGNTACG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6804b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_json(\"entrenamiento_v2/results/training_results/final_results_20250630_190524.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e24969af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('datos/clean_gtdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e56cbaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>gc_content</th>\n",
       "      <th>domain</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RS_GCF_000657795.2</td>\n",
       "      <td>CTGAAGAGTTTGATCCTGGCTCAGATTGAACGCTGGCGGGATGCTT...</td>\n",
       "      <td>1528</td>\n",
       "      <td>55.562827</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Pseudomonadota</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Burkholderiales</td>\n",
       "      <td>Burkholderiaceae</td>\n",
       "      <td>Bordetella</td>\n",
       "      <td>Bordetella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RS_GCF_000019185.1</td>\n",
       "      <td>ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCC...</td>\n",
       "      <td>1542</td>\n",
       "      <td>54.409857</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Pseudomonadota</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Enterobacterales</td>\n",
       "      <td>Shewanellaceae</td>\n",
       "      <td>Shewanella</td>\n",
       "      <td>Shewanella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RS_GCF_004570605.1</td>\n",
       "      <td>CATGAGAGTTTGATCCTGGCTCAGGACAAACGCTGGCGGCGTGCCT...</td>\n",
       "      <td>1547</td>\n",
       "      <td>52.230123</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Bacillota</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Aerococcaceae</td>\n",
       "      <td>WM01</td>\n",
       "      <td>WM01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RS_GCF_002245655.1</td>\n",
       "      <td>CTTAAGAGTTTGATCCTGGCTCAGATTGAACGCTGGCGGCATGCTT...</td>\n",
       "      <td>1536</td>\n",
       "      <td>56.119792</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Pseudomonadota</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Burkholderiales</td>\n",
       "      <td>Rhodocyclaceae</td>\n",
       "      <td>Thauera</td>\n",
       "      <td>Thauera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RS_GCF_016863255.1</td>\n",
       "      <td>GTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCT...</td>\n",
       "      <td>1518</td>\n",
       "      <td>60.276680</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Actinomycetota</td>\n",
       "      <td>Actinomycetes</td>\n",
       "      <td>Mycobacteriales</td>\n",
       "      <td>Micromonosporaceae</td>\n",
       "      <td>Planosporangium</td>\n",
       "      <td>Planosporangium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38623</th>\n",
       "      <td>39170</td>\n",
       "      <td>RS_GCF_004348725.1</td>\n",
       "      <td>ACGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCTT...</td>\n",
       "      <td>1517</td>\n",
       "      <td>58.404746</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Actinomycetota</td>\n",
       "      <td>Actinomycetes</td>\n",
       "      <td>Propionibacteriales</td>\n",
       "      <td>Kribbellaceae</td>\n",
       "      <td>Kribbella</td>\n",
       "      <td>Kribbella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38624</th>\n",
       "      <td>39171</td>\n",
       "      <td>RS_GCF_003097655.1</td>\n",
       "      <td>CTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCCT...</td>\n",
       "      <td>1533</td>\n",
       "      <td>53.620352</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Bacteroidota</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Flavobacteriales</td>\n",
       "      <td>Flavobacteriaceae</td>\n",
       "      <td>Flavobacterium</td>\n",
       "      <td>Flavobacterium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38625</th>\n",
       "      <td>39172</td>\n",
       "      <td>GB_GCA_016714985.1</td>\n",
       "      <td>ACGGAGAGTTTGATCCTGGCTCAGGATGAACGCTAGCGGGAGGCCT...</td>\n",
       "      <td>1525</td>\n",
       "      <td>56.327869</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Bacteroidota</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Chitinophagales</td>\n",
       "      <td>Saprospiraceae</td>\n",
       "      <td>UBA6168</td>\n",
       "      <td>UBA6168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38626</th>\n",
       "      <td>39173</td>\n",
       "      <td>GB_GCA_030603665.1</td>\n",
       "      <td>ATTAAAGCTCCGGCGCTTCGGGATGGGCCTGCGGCCGATTAGCTAG...</td>\n",
       "      <td>1305</td>\n",
       "      <td>56.551724</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Chloroflexota</td>\n",
       "      <td>Anaerolineae</td>\n",
       "      <td>UBA7937</td>\n",
       "      <td>B3-Chlor</td>\n",
       "      <td>JAUVXJ01</td>\n",
       "      <td>JAUVXJ01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38627</th>\n",
       "      <td>39174</td>\n",
       "      <td>GB_GCA_900552395.1</td>\n",
       "      <td>CGGAGAGTTCGATCCTGGCTCAGGATGAACGCTGGCGGCGCGCCTA...</td>\n",
       "      <td>1502</td>\n",
       "      <td>65.446072</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Actinomycetota</td>\n",
       "      <td>Coriobacteriia</td>\n",
       "      <td>Coriobacteriales</td>\n",
       "      <td>Coriobacteriaceae</td>\n",
       "      <td>Collinsella</td>\n",
       "      <td>Collinsella</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38628 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index         sequence_id  \\\n",
       "0          0  RS_GCF_000657795.2   \n",
       "1          1  RS_GCF_000019185.1   \n",
       "2          2  RS_GCF_004570605.1   \n",
       "3          3  RS_GCF_002245655.1   \n",
       "4          4  RS_GCF_016863255.1   \n",
       "...      ...                 ...   \n",
       "38623  39170  RS_GCF_004348725.1   \n",
       "38624  39171  RS_GCF_003097655.1   \n",
       "38625  39172  GB_GCA_016714985.1   \n",
       "38626  39173  GB_GCA_030603665.1   \n",
       "38627  39174  GB_GCA_900552395.1   \n",
       "\n",
       "                                                sequence  sequence_length  \\\n",
       "0      CTGAAGAGTTTGATCCTGGCTCAGATTGAACGCTGGCGGGATGCTT...             1528   \n",
       "1      ATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCC...             1542   \n",
       "2      CATGAGAGTTTGATCCTGGCTCAGGACAAACGCTGGCGGCGTGCCT...             1547   \n",
       "3      CTTAAGAGTTTGATCCTGGCTCAGATTGAACGCTGGCGGCATGCTT...             1536   \n",
       "4      GTTGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCT...             1518   \n",
       "...                                                  ...              ...   \n",
       "38623  ACGGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCTT...             1517   \n",
       "38624  CTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCCT...             1533   \n",
       "38625  ACGGAGAGTTTGATCCTGGCTCAGGATGAACGCTAGCGGGAGGCCT...             1525   \n",
       "38626  ATTAAAGCTCCGGCGCTTCGGGATGGGCCTGCGGCCGATTAGCTAG...             1305   \n",
       "38627  CGGAGAGTTCGATCCTGGCTCAGGATGAACGCTGGCGGCGCGCCTA...             1502   \n",
       "\n",
       "       gc_content    domain          phylum                class  \\\n",
       "0       55.562827  Bacteria  Pseudomonadota  Gammaproteobacteria   \n",
       "1       54.409857  Bacteria  Pseudomonadota  Gammaproteobacteria   \n",
       "2       52.230123  Bacteria       Bacillota              Bacilli   \n",
       "3       56.119792  Bacteria  Pseudomonadota  Gammaproteobacteria   \n",
       "4       60.276680  Bacteria  Actinomycetota        Actinomycetes   \n",
       "...           ...       ...             ...                  ...   \n",
       "38623   58.404746  Bacteria  Actinomycetota        Actinomycetes   \n",
       "38624   53.620352  Bacteria    Bacteroidota          Bacteroidia   \n",
       "38625   56.327869  Bacteria    Bacteroidota          Bacteroidia   \n",
       "38626   56.551724  Bacteria   Chloroflexota         Anaerolineae   \n",
       "38627   65.446072  Bacteria  Actinomycetota       Coriobacteriia   \n",
       "\n",
       "                     order              family            genus  \\\n",
       "0          Burkholderiales    Burkholderiaceae       Bordetella   \n",
       "1         Enterobacterales      Shewanellaceae       Shewanella   \n",
       "2          Lactobacillales       Aerococcaceae             WM01   \n",
       "3          Burkholderiales      Rhodocyclaceae          Thauera   \n",
       "4          Mycobacteriales  Micromonosporaceae  Planosporangium   \n",
       "...                    ...                 ...              ...   \n",
       "38623  Propionibacteriales       Kribbellaceae        Kribbella   \n",
       "38624     Flavobacteriales   Flavobacteriaceae   Flavobacterium   \n",
       "38625      Chitinophagales      Saprospiraceae          UBA6168   \n",
       "38626              UBA7937            B3-Chlor         JAUVXJ01   \n",
       "38627     Coriobacteriales   Coriobacteriaceae      Collinsella   \n",
       "\n",
       "               species  \n",
       "0           Bordetella  \n",
       "1           Shewanella  \n",
       "2                 WM01  \n",
       "3              Thauera  \n",
       "4      Planosporangium  \n",
       "...                ...  \n",
       "38623        Kribbella  \n",
       "38624   Flavobacterium  \n",
       "38625          UBA6168  \n",
       "38626         JAUVXJ01  \n",
       "38627      Collinsella  \n",
       "\n",
       "[38628 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cfe701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d40342",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/training_results/final_results.json\", 'r') as f:\n",
    "        data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab022fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "f1_score_weighted\n",
      "f1_score_macro\n",
      "precision_weighted\n",
      "precision_macro\n",
      "recall_weighted\n",
      "recall_macro\n",
      "sensitivity_per_class\n",
      "specificity_per_class\n",
      "precision_per_class\n",
      "recall_per_class\n"
     ]
    }
   ],
   "source": [
    "for i in data['results'][0]['metrics'].keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a23aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['model_name', 'encoding', 'parameters', 'training_time', 'model_file', 'metadata_file']\n",
    "metricas=['accuracy', 'f1_score_weighted', 'f1_score_macro', 'precision_weighted', 'precision_macro', 'recall_weighted', 'recall_macro']\n",
    "\n",
    "df={}\n",
    "for c in cols+metricas:\n",
    "    df[c]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40aca7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['results'])):\n",
    "    for c in cols:\n",
    "        df[c].append(data['results'][i][c])\n",
    "    for m in metricas:\n",
    "        df[m].append(data['results'][i]['metrics'][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "612dc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"results/training_results/resultados_entrenamiento_resumen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c620498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AS_FFT\n",
      "Random Forest AS_K-mers\n",
      "Random Forest AS_K-mers + FFT\n",
      "Random Forest AS_K-mers + Wavelet\n",
      "Random Forest AS_One Hot\n",
      "Random Forest AS_One Hot + FFT\n",
      "Random Forest AS_One Hot + Wavelet\n",
      "Random Forest AS_Wavelet\n",
      "Random Forest PS_FFT\n",
      "Random Forest PS_K-mers\n",
      "Random Forest PS_K-mers + FFT\n",
      "Random Forest PS_K-mers + Wavelet\n",
      "Random Forest PS_One Hot\n",
      "Random Forest PS_One Hot + FFT\n",
      "Random Forest PS_One Hot + Wavelet\n",
      "Random Forest PS_Wavelet\n",
      "SVM AS_FFT\n",
      "SVM AS_K-mers\n",
      "SVM AS_K-mers + FFT\n",
      "SVM AS_K-mers + Wavelet\n",
      "SVM AS_One Hot\n",
      "SVM AS_One Hot + FFT\n",
      "SVM AS_One Hot + Wavelet\n",
      "SVM AS_Wavelet\n",
      "SVM PS_FFT\n",
      "SVM PS_K-mers\n",
      "SVM PS_K-mers + FFT\n",
      "SVM PS_K-mers + Wavelet\n",
      "SVM PS_One Hot\n",
      "SVM PS_One Hot + FFT\n",
      "SVM PS_One Hot + Wavelet\n",
      "SVM PS_Wavelet\n",
      "XGBoost AS_FFT\n",
      "XGBoost AS_K-mers\n",
      "XGBoost AS_K-mers + FFT\n",
      "XGBoost AS_K-mers + Wavelet\n",
      "XGBoost AS_One Hot\n",
      "XGBoost AS_One Hot + FFT\n",
      "XGBoost AS_One Hot + Wavelet\n",
      "XGBoost AS_Wavelet\n",
      "XGBoost PS_FFT\n",
      "XGBoost PS_K-mers\n",
      "XGBoost PS_K-mers + FFT\n",
      "XGBoost PS_K-mers + Wavelet\n",
      "XGBoost PS_One Hot\n",
      "XGBoost PS_One Hot + FFT\n",
      "XGBoost PS_One Hot + Wavelet\n",
      "XGBoost PS_Wavelet\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(df)\n",
    "for i,j in df[['model_name',\t'encoding']].sort_values(by=['model_name',\t'encoding']).values:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f28bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = glob.glob('sv/results/gridsearch_results/*.json')\n",
    "all_data = []\n",
    "\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f458e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df={\n",
    "    'modelo':[],\n",
    "    'encoding':[],\n",
    "    'best_params':[]\n",
    "}\n",
    "\n",
    "for j in all_data:\n",
    "    df['modelo'].append(j['algorithm'])\n",
    "    df['encoding'].append(j['encoding'])\n",
    "    df['best_params'].append(j['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3067f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53dd863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>encoding</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_FFT</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_K-mers + FFT</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_K-mers + Wavelet</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_K-mers</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_One Hot + FFT</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_One Hot + Wavelet</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_One Hot</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AS_Wavelet</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_FFT</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_K-mers + FFT</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_K-mers + Wavelet</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_K-mers</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_One Hot + FFT</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_One Hot + Wavelet</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_One Hot</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>PS_Wavelet</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_split': 2, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_FFT</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_K-mers + FFT</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_K-mers + Wavelet</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_K-mers</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_One Hot + FFT</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_One Hot + Wavelet</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_One Hot</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AS_Wavelet</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_FFT</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_K-mers + FFT</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_K-mers + Wavelet</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_K-mers</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_One Hot + FFT</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_One Hot + Wavelet</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_One Hot</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM</td>\n",
       "      <td>PS_Wavelet</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          modelo              encoding  \\\n",
       "0   RandomForest                AS_FFT   \n",
       "1   RandomForest       AS_K-mers + FFT   \n",
       "2   RandomForest   AS_K-mers + Wavelet   \n",
       "3   RandomForest             AS_K-mers   \n",
       "4   RandomForest      AS_One Hot + FFT   \n",
       "5   RandomForest  AS_One Hot + Wavelet   \n",
       "6   RandomForest            AS_One Hot   \n",
       "7   RandomForest            AS_Wavelet   \n",
       "8   RandomForest                PS_FFT   \n",
       "9   RandomForest       PS_K-mers + FFT   \n",
       "10  RandomForest   PS_K-mers + Wavelet   \n",
       "11  RandomForest             PS_K-mers   \n",
       "12  RandomForest      PS_One Hot + FFT   \n",
       "13  RandomForest  PS_One Hot + Wavelet   \n",
       "14  RandomForest            PS_One Hot   \n",
       "15  RandomForest            PS_Wavelet   \n",
       "16           SVM                AS_FFT   \n",
       "17           SVM       AS_K-mers + FFT   \n",
       "18           SVM   AS_K-mers + Wavelet   \n",
       "19           SVM             AS_K-mers   \n",
       "20           SVM      AS_One Hot + FFT   \n",
       "21           SVM  AS_One Hot + Wavelet   \n",
       "22           SVM            AS_One Hot   \n",
       "23           SVM            AS_Wavelet   \n",
       "24           SVM                PS_FFT   \n",
       "25           SVM       PS_K-mers + FFT   \n",
       "26           SVM   PS_K-mers + Wavelet   \n",
       "27           SVM             PS_K-mers   \n",
       "28           SVM      PS_One Hot + FFT   \n",
       "29           SVM  PS_One Hot + Wavelet   \n",
       "30           SVM            PS_One Hot   \n",
       "31           SVM            PS_Wavelet   \n",
       "\n",
       "                                          best_params  \n",
       "0   {'max_depth': 10, 'min_samples_split': 5, 'n_e...  \n",
       "1   {'max_depth': None, 'min_samples_split': 10, '...  \n",
       "2   {'max_depth': 20, 'min_samples_split': 10, 'n_...  \n",
       "3   {'max_depth': 10, 'min_samples_split': 10, 'n_...  \n",
       "4   {'max_depth': 10, 'min_samples_split': 5, 'n_e...  \n",
       "5   {'max_depth': None, 'min_samples_split': 5, 'n...  \n",
       "6   {'max_depth': None, 'min_samples_split': 5, 'n...  \n",
       "7   {'max_depth': 20, 'min_samples_split': 5, 'n_e...  \n",
       "8   {'max_depth': 20, 'min_samples_split': 10, 'n_...  \n",
       "9   {'max_depth': 30, 'min_samples_split': 10, 'n_...  \n",
       "10  {'max_depth': 20, 'min_samples_split': 2, 'n_e...  \n",
       "11  {'max_depth': None, 'min_samples_split': 5, 'n...  \n",
       "12  {'max_depth': 30, 'min_samples_split': 10, 'n_...  \n",
       "13  {'max_depth': 20, 'min_samples_split': 5, 'n_e...  \n",
       "14  {'max_depth': None, 'min_samples_split': 5, 'n...  \n",
       "15  {'max_depth': 20, 'min_samples_split': 2, 'n_e...  \n",
       "16        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "17        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "18       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "19        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "20       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "21       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "22       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "23      {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "24   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  \n",
       "25   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  \n",
       "26   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  \n",
       "27   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  \n",
       "28   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  \n",
       "29       {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  \n",
       "30       {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  \n",
       "31   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['modelo']!='XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a75569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos/params_gridsearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3791db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce3ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux=[]\n",
    "for f in os.listdir(\"0.otros/partes_xgboost_gs/gs_terminado/results/gridsearch_results\"):\n",
    "    with open(f\"0.otros/partes_xgboost_gs/gs_terminado/results/gridsearch_results/{f}\", 'r') as file:\n",
    "        aux.append(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3bddafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 6,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux[0]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b008f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'AS_FFT':{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.7},\n",
      " 'AS_K-mers + FFT':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8},\n",
      " 'AS_K-mers + Wavelet':{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.7},\n",
      " 'AS_K-mers':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.9},\n",
      " 'AS_One Hot + FFT':{'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8},\n",
      " 'AS_One Hot + Wavelet':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8},\n",
      " 'AS_One Hot':{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.7},\n",
      " 'AS_Wavelet':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7},\n",
      " 'PS_FFT':{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.9},\n",
      " 'PS_K-mers + FFT':{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.7},\n",
      " 'PS_K-mers + Wavelet':{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 50, 'subsample': 0.7},\n",
      " 'PS_K-mers':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.8},\n",
      " 'PS_One Hot + FFT':{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8},\n",
      " 'PS_One Hot + Wavelet':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.9},\n",
      " 'PS_One Hot':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8},\n",
      " 'PS_Wavelet':{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.8},\n"
     ]
    }
   ],
   "source": [
    "for i in aux:\n",
    "    # print(i['best_params'])\n",
    "    print(f\"\"\" \\'{i['encoding']}\\':{i['best_params']},\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e66b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Procesando Pelagibacter ---\n",
      "Buscando secuencias para Pelagibacter...\n",
      "Encontradas 101 secuencias\n",
      "Descargando lote 1...\n",
      "Descargando lote 2...\n",
      "Descargando lote 3...\n",
      "Secuencias válidas obtenidas: 96\n",
      "Guardado: datos_nuevos/nuevas_pelagibacter.csv\n",
      "\n",
      "Total descargado: 96 secuencias\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def download_genus_sequences(genus_name, email, max_sequences=1000):\n",
    "    \"\"\"Descargar secuencias 16S para un género específico\"\"\"\n",
    "    \n",
    "    # Configurar email (requerido por NCBI)\n",
    "    Entrez.email = email\n",
    "    \n",
    "    # Buscar secuencias\n",
    "    search_term = f'\"{genus_name}\"[Organism] AND 16S[Title] AND 1300:1600[Sequence Length]'\n",
    "    \n",
    "    print(f\"Buscando secuencias para {genus_name}...\")\n",
    "    \n",
    "    # Realizar búsqueda\n",
    "    handle = Entrez.esearch(db=\"nucleotide\", term=search_term, retmax=max_sequences)\n",
    "    search_results = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    \n",
    "    id_list = search_results[\"IdList\"]\n",
    "    print(f\"Encontradas {len(id_list)} secuencias\")\n",
    "    \n",
    "    if not id_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Descargar secuencias en lotes de 50\n",
    "    sequences = []\n",
    "    batch_size = 50\n",
    "    \n",
    "    for i in range(0, len(id_list), batch_size):\n",
    "        batch_ids = id_list[i:i+batch_size]\n",
    "        \n",
    "        print(f\"Descargando lote {i//batch_size + 1}...\")\n",
    "        \n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=batch_ids, rettype=\"fasta\", retmode=\"text\")\n",
    "        batch_sequences = list(SeqIO.parse(handle, \"fasta\"))\n",
    "        sequences.extend(batch_sequences)\n",
    "        handle.close()\n",
    "        \n",
    "        time.sleep(0.5)  # Pausa para no sobrecargar NCBI\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    records = []\n",
    "    for record in sequences:\n",
    "        sequence = str(record.seq).upper()\n",
    "        \n",
    "        # Filtrar solo ACGT y N\n",
    "        if not set(sequence).issubset({'A', 'C', 'G', 'T', 'N'}):\n",
    "            continue\n",
    "        \n",
    "        gc_count = sequence.count('G') + sequence.count('C')\n",
    "        gc_content = (gc_count / len(sequence)) * 100\n",
    "        \n",
    "        records.append({\n",
    "            'sequence_id': record.id,\n",
    "            'sequence': sequence,\n",
    "            'sequence_length': len(sequence),\n",
    "            'gc_content': gc_content,\n",
    "            'genus': genus_name\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"Secuencias válidas obtenidas: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Lista de todos los géneros\n",
    "genera_necesarios = [\n",
    "    # \"Streptomyces\",\n",
    "    # \"Pelagibacter\", \n",
    "    # \"Pseudomonas\",\n",
    "    # \"Streptococcus\",\n",
    "    # \"Mycobacterium\",\n",
    "    # \"Flavobacterium\",\n",
    "    # \"Microbacterium\",\n",
    "    # \"Prochlorococcus\",\n",
    "    # \"Bradyrhizobium\",\n",
    "    # \"Sphingomonas\",\n",
    "    # \"Corynebacterium\",\n",
    "    # \"Vibrio\",\n",
    "    # \"Arthrobacter\",\n",
    "    # \"Chryseobacterium\",\n",
    "    # \"Acinetobacter\",\n",
    "    # \"Nocardioides\",\n",
    "    # \"Rhizobium\",\n",
    "    # \"Collinsella\",\n",
    "    # \"Micromonospora\",\n",
    "    # \"Mesorhizobium\",\n",
    "    # \"Nocardia\",\n",
    "    # \"Bifidobacterium\",\n",
    "    \"Pelagibacter\",\n",
    "    # \"Paraburkholderia\",\n",
    "    # \"Polynucleobacter\",\n",
    "    # \"Pedobacter\",\n",
    "    # \"Prevotella\",\n",
    "    # \"Paracoccus\",\n",
    "    # \"Novosphingobium\",\n",
    "    # \"Methylobacterium\"\n",
    "]\n",
    "\n",
    "def descargar_todos_los_generos(email):\n",
    "    \"\"\"Descargar secuencias para todos los géneros necesarios\"\"\"\n",
    "    \n",
    "    todos_los_datos = []\n",
    "    \n",
    "    for genus in genera_necesarios:\n",
    "        print(f\"\\n--- Procesando {genus} ---\")\n",
    "        \n",
    "        df_genus = download_genus_sequences(genus, email)\n",
    "        \n",
    "        if not df_genus.empty:\n",
    "            # Guardar archivo individual\n",
    "            filename = f\"datos_nuevos/nuevas_{genus.lower()}.csv\"\n",
    "            df_genus.to_csv(filename, index=False)\n",
    "            print(f\"Guardado: {filename}\")\n",
    "            \n",
    "            todos_los_datos.append(df_genus)\n",
    "        \n",
    "        time.sleep(2)  # Pausa entre géneros\n",
    "    \n",
    "    # Combinar todos\n",
    "    if todos_los_datos:\n",
    "        df_completo = pd.concat(todos_los_datos, ignore_index=True)\n",
    "        df_completo.to_csv(\"nuevas_secuencias_completo.csv\", index=False)\n",
    "        print(f\"\\nTotal descargado: {len(df_completo)} secuencias\")\n",
    "        return df_completo\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Uso:\n",
    "EMAIL = \"123diego721@gmail.com\"  # CAMBIAR POR TU EMAIL\n",
    "df_nuevos = descargar_todos_los_generos(EMAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd818217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "def parse_taxonomy(description):\n",
    "    \"\"\"Extraer información taxonómica completa de la descripción\"\"\"\n",
    "    \n",
    "    # Patrón para taxonomía completa formato NCBI\n",
    "    tax_match = re.search(r'd__([^;]+);p__([^;]+);c__([^;]+);o__([^;]+);f__([^;]+);g__([^;]+);s__([^\\s]+)', description)\n",
    "    \n",
    "    if tax_match:\n",
    "        return {\n",
    "            'domain': tax_match.group(1).strip(),\n",
    "            'phylum': tax_match.group(2).strip(),\n",
    "            'class': tax_match.group(3).strip(),\n",
    "            'order': tax_match.group(4).strip(),\n",
    "            'family': tax_match.group(5).strip(),\n",
    "            'genus': tax_match.group(6).strip(),\n",
    "            'species': tax_match.group(7).strip()\n",
    "        }\n",
    "    \n",
    "    # Patrón alternativo sin underscores\n",
    "    tax_match2 = re.search(r'd([^;]+);p([^;]+);c([^;]+);o([^;]+);f([^;]+);g([^;]+);s__([^\\s]+)', description)\n",
    "    \n",
    "    if tax_match2:\n",
    "        return {\n",
    "            'domain': tax_match2.group(1).strip(),\n",
    "            'phylum': tax_match2.group(2).strip(),\n",
    "            'class': tax_match2.group(3).strip(),\n",
    "            'order': tax_match2.group(4).strip(),\n",
    "            'family': tax_match2.group(5).strip(),\n",
    "            'genus': tax_match2.group(6).strip(),\n",
    "            'species': tax_match2.group(7).strip()\n",
    "        }\n",
    "    \n",
    "    # Si no encuentra patrón completo, buscar organismo entre corchetes\n",
    "    org_match = re.search(r'\\[([^\\]]+)\\]', description)\n",
    "    organism = org_match.group(1) if org_match else \"Unknown\"\n",
    "    \n",
    "    # Intentar extraer genus y species del organismo\n",
    "    if ' ' in organism:\n",
    "        parts = organism.split()\n",
    "        genus_name = parts[0]\n",
    "        species_name = ' '.join(parts[1:]) if len(parts) > 1 else \"sp.\"\n",
    "    else:\n",
    "        genus_name = organism\n",
    "        species_name = \"sp.\"\n",
    "    \n",
    "    return {\n",
    "        'domain': 'Bacteria',\n",
    "        'phylum': 'Unknown',\n",
    "        'class': 'Unknown', \n",
    "        'order': 'Unknown',\n",
    "        'family': 'Unknown',\n",
    "        'genus': genus_name,\n",
    "        'species': species_name\n",
    "    }\n",
    "\n",
    "def download_genus_sequences(genus_name, email, max_sequences=300):\n",
    "    \"\"\"Descargar secuencias 16S para un género específico con taxonomía completa\"\"\"\n",
    "    \n",
    "    # Configurar email (requerido por NCBI)\n",
    "    Entrez.email = email\n",
    "    \n",
    "    # Buscar secuencias\n",
    "    search_term = f'\"{genus_name}\"[Organism] AND 16S[Title] AND 1300:1600[Sequence Length]'\n",
    "    \n",
    "    print(f\"Buscando secuencias para {genus_name}...\")\n",
    "    \n",
    "    # Realizar búsqueda\n",
    "    handle = Entrez.esearch(db=\"nucleotide\", term=search_term, retmax=max_sequences)\n",
    "    search_results = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    \n",
    "    id_list = search_results[\"IdList\"]\n",
    "    print(f\"Encontradas {len(id_list)} secuencias\")\n",
    "    \n",
    "    if not id_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Descargar secuencias en lotes de 50\n",
    "    sequences = []\n",
    "    batch_size = 50\n",
    "    \n",
    "    for i in range(0, len(id_list), batch_size):\n",
    "        batch_ids = id_list[i:i+batch_size]\n",
    "        \n",
    "        print(f\"Descargando lote {i//batch_size + 1}...\")\n",
    "        \n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=batch_ids, rettype=\"fasta\", retmode=\"text\")\n",
    "        batch_sequences = list(SeqIO.parse(handle, \"fasta\"))\n",
    "        sequences.extend(batch_sequences)\n",
    "        handle.close()\n",
    "        \n",
    "        time.sleep(0.5)  # Pausa para no sobrecargar NCBI\n",
    "    \n",
    "    # Convertir a DataFrame con taxonomía\n",
    "    records = []\n",
    "    for record in sequences:\n",
    "        sequence = str(record.seq).upper()\n",
    "        \n",
    "        # Filtrar solo ACGT y N\n",
    "        if not set(sequence).issubset({'A', 'C', 'G', 'T', 'N'}):\n",
    "            continue\n",
    "        \n",
    "        gc_count = sequence.count('G') + sequence.count('C')\n",
    "        gc_content = (gc_count / len(sequence)) * 100\n",
    "        \n",
    "        # Extraer información taxonómica\n",
    "        taxonomy = parse_taxonomy(record.description)\n",
    "        \n",
    "        record_data = {\n",
    "            'sequence_id': record.id,\n",
    "            'sequence': sequence,\n",
    "            'sequence_length': len(sequence),\n",
    "            'gc_content': gc_content,\n",
    "            'description': record.description\n",
    "        }\n",
    "        \n",
    "        # Añadir información taxonómica\n",
    "        record_data.update(taxonomy)\n",
    "        \n",
    "        records.append(record_data)\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"Secuencias válidas obtenidas: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Lista de todos los géneros\n",
    "genera_necesarios = [\n",
    "    \"Streptomyces\",\n",
    "    \"Pelagibacter\", \n",
    "    \"Pseudomonas\",\n",
    "    \"Streptococcus\",\n",
    "    \"Mycobacterium\",\n",
    "    \"Flavobacterium\",\n",
    "    \"Microbacterium\",\n",
    "    \"Prochlorococcus\",\n",
    "    \"Bradyrhizobium\",\n",
    "    \"Sphingomonas\",\n",
    "    \"Corynebacterium\",\n",
    "    \"Vibrio\",\n",
    "    \"Arthrobacter\",\n",
    "    \"Chryseobacterium\",\n",
    "    \"Acinetobacter\",\n",
    "    \"Nocardioides\",\n",
    "    \"Rhizobium\",\n",
    "    \"Collinsella\",\n",
    "    \"Micromonospora\",\n",
    "    \"Mesorhizobium\",\n",
    "    \"Nocardia\",\n",
    "    \"Bifidobacterium\",\n",
    "    \"Pelagibacter\",\n",
    "    \"Paraburkholderia\",\n",
    "    \"Polynucleobacter\",\n",
    "    \"Pedobacter\",\n",
    "    \"Prevotella\",\n",
    "    \"Paracoccus\",\n",
    "    \"Novosphingobium\",\n",
    "    \"Methylobacterium\"\n",
    "]\n",
    "\n",
    "def descargar_todos_los_generos(email):\n",
    "    \"\"\"Descargar secuencias para todos los géneros con taxonomía completa\"\"\"\n",
    "    \n",
    "    todos_los_datos = []\n",
    "    \n",
    "    for genus in genera_necesarios:\n",
    "        print(f\"\\n--- Procesando {genus} ---\")\n",
    "        \n",
    "        df_genus = download_genus_sequences(genus, email)\n",
    "        \n",
    "        if not df_genus.empty:\n",
    "            # Guardar archivo individual\n",
    "            filename = f\"nuevas_{genus.lower()}_taxonomia.csv\"\n",
    "            df_genus.to_csv(filename, index=False)\n",
    "            print(f\"Guardado: {filename}\")\n",
    "            \n",
    "            todos_los_datos.append(df_genus)\n",
    "        \n",
    "        time.sleep(2)  # Pausa entre géneros\n",
    "    \n",
    "    # Combinar todos\n",
    "    if todos_los_datos:\n",
    "        df_completo = pd.concat(todos_los_datos, ignore_index=True)\n",
    "        df_completo.to_csv(\"nuevas_secuencias_completo_taxonomia.csv\", index=False)\n",
    "        print(f\"\\nTotal descargado: {len(df_completo)} secuencias\")\n",
    "        \n",
    "        # Mostrar estadísticas taxonómicas\n",
    "        print(\"\\nEstadísticas taxonómicas:\")\n",
    "        print(f\"Dominios: {df_completo['domain'].nunique()}\")\n",
    "        print(f\"Phyla: {df_completo['phylum'].nunique()}\")\n",
    "        print(f\"Clases: {df_completo['class'].nunique()}\")\n",
    "        print(f\"Órdenes: {df_completo['order'].nunique()}\")\n",
    "        print(f\"Familias: {df_completo['family'].nunique()}\")\n",
    "        print(f\"Géneros: {df_completo['genus'].nunique()}\")\n",
    "        print(f\"Especies: {df_completo['species'].nunique()}\")\n",
    "        \n",
    "        return df_completo\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Uso:\n",
    "EMAIL = \"dsantibanezo@utem.cl\"  # CAMBIAR POR TU EMAIL\n",
    "df_nuevos = descargar_todos_los_generos(EMAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214122a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f433eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"datos/datos_filtrados_sin_encoding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8766f7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origen\n",
       "gtdb      4200\n",
       "entrez    1600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['purpose']==0]['origen'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
