{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2a627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "df=pd.read_csv('datos/datos_filtrados_sin_encoding.csv')\n",
    "df=df.rename(columns={'sequence':'aligned_sequence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f31a531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "genus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d74526f7-8bba-440c-8591-6a98ac727374",
       "rows": [
        [
         "Streptomyces",
         "802"
        ],
        [
         "Pelagibacter",
         "657"
        ],
        [
         "Pseudomonas_E",
         "560"
        ],
        [
         "Streptococcus",
         "343"
        ],
        [
         "Mycobacterium",
         "257"
        ],
        [
         "Flavobacterium",
         "245"
        ],
        [
         "Microbacterium",
         "162"
        ],
        [
         "Prochlorococcus_A",
         "113"
        ],
        [
         "Bradyrhizobium",
         "109"
        ],
        [
         "Sphingomonas",
         "104"
        ],
        [
         "Corynebacterium",
         "81"
        ],
        [
         "Vibrio",
         "63"
        ],
        [
         "Arthrobacter",
         "60"
        ],
        [
         "Chryseobacterium",
         "52"
        ],
        [
         "Acinetobacter",
         "50"
        ],
        [
         "Nocardioides",
         "49"
        ],
        [
         "Rhizobium",
         "29"
        ],
        [
         "Collinsella",
         "28"
        ],
        [
         "Micromonospora",
         "23"
        ],
        [
         "Mesorhizobium",
         "22"
        ],
        [
         "Nocardia",
         "17"
        ],
        [
         "Bifidobacterium",
         "8"
        ],
        [
         "Pelagibacter_A",
         "4"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 23
       }
      },
      "text/plain": [
       "genus\n",
       "Streptomyces         802\n",
       "Pelagibacter         657\n",
       "Pseudomonas_E        560\n",
       "Streptococcus        343\n",
       "Mycobacterium        257\n",
       "Flavobacterium       245\n",
       "Microbacterium       162\n",
       "Prochlorococcus_A    113\n",
       "Bradyrhizobium       109\n",
       "Sphingomonas         104\n",
       "Corynebacterium       81\n",
       "Vibrio                63\n",
       "Arthrobacter          60\n",
       "Chryseobacterium      52\n",
       "Acinetobacter         50\n",
       "Nocardioides          49\n",
       "Rhizobium             29\n",
       "Collinsella           28\n",
       "Micromonospora        23\n",
       "Mesorhizobium         22\n",
       "Nocardia              17\n",
       "Bifidobacterium        8\n",
       "Pelagibacter_A         4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_training']==False]['genus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404a3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['genus', 'se', 'sequence','gc_content']]\n",
    "# df=df.rename(columns={'se':'as'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd75fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding de secuencias para igualar el largo de las mismas entre las más largas y las más cortas\n",
    "def pad_sequences(sequences, maxlen):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < maxlen:\n",
    "            seq += 'N' * (maxlen - len(seq))  \n",
    "        else:\n",
    "            seq = seq[:maxlen]  # Trunca si es la secuencia es más largo que la variable maxlen\n",
    "        padded_sequences.append(seq)\n",
    "    return padded_sequences\n",
    "\n",
    "maxlen = max([len(i) for i in df['original_sequence']]) \n",
    "df['padded_sequences'] = pad_sequences(df['original_sequence'], maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68123c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['len_sequence']=[len(i) for i in df['sequence']]\n",
    "df['len_ps']=[len(i) for i in df['padded_sequences']]\n",
    "df['len_as']=[len(i) for i in df['aligned_sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde1291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['genus', 'gc_content', 'sequence', 'len_sequence', 'ps','len_ps','as','len_as']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451a03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_genus={j:i for i,j in enumerate(df['genus'].unique())}\n",
    "df['clases_modelos']=df['genus'].map(map_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f99dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'genus':map_genus.keys(), 'model_class':map_genus.values()}).to_csv('datos/mapeo_clases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc47cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from scipy.fft import fft\n",
    "from itertools import product\n",
    "\n",
    "def fourier(sequences, is_str=True):\n",
    "    if is_str:\n",
    "        templist=[]\n",
    "        for seq in sequences:\n",
    "            num_seq=[ord(char) for char in seq]\n",
    "            fft_seq=fft(num_seq)\n",
    "            fft_seq=np.abs(fft_seq)\n",
    "            # fft_seq=fft[1:len(fft_seq)//2]\n",
    "            templist.append(fft_seq[1:len(fft_seq)//2])\n",
    "        return templist\n",
    "    else:\n",
    "        templist=[]\n",
    "        for seq in sequences:\n",
    "            fft_seq=fft(seq)\n",
    "            fft_seq=np.abs(fft_seq)\n",
    "            # fft_seq=fft[1:len(fft_seq)//2]\n",
    "            templist.append(fft_seq[1:len(fft_seq)//2])\n",
    "        return templist\n",
    "\n",
    "def generate_kmers_dict(k, unique_chars=set('ACGNT')):\n",
    "    \n",
    "    # Generar todas las posibles combinaciones\n",
    "    kmers = product(unique_chars, repeat=k)\n",
    "    \n",
    "    # Crear el diccionario\n",
    "    kmer_dict = {''.join(kmer): i for i,kmer in enumerate(kmers)}\n",
    "    \n",
    "    return kmer_dict\n",
    "\n",
    "\n",
    "def k_mers(sequencias, k=3, unique_chars=set('ACGNT')):\n",
    "\n",
    "    kmers_map=generate_kmers_dict(k, unique_chars)\n",
    "    templist=[]\n",
    "    for seq in sequencias:\n",
    "        temp=[seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "        templist.append([kmers_map[i] for i in temp])\n",
    "    return templist\n",
    "\n",
    "def one_hot(sequences, max_len, unique_chars=set('ACGNT'), reshape=True):\n",
    "    mapping={j:i for i,j in enumerate(unique_chars)}\n",
    "    sequencias_procesadas=[]\n",
    "    if reshape==True:\n",
    "        for s in sequences:\n",
    "            temp=np.zeros((max_len,len(unique_chars)))\n",
    "            for c in zip(s,temp):\n",
    "                    c[1][mapping[c[0]]]=1\n",
    "            sequencias_procesadas.append(temp.reshape(-1))\n",
    "        return sequencias_procesadas\n",
    "    elif reshape==False:\n",
    "        for s in sequences:\n",
    "            temp=np.zeros((max_len,len(unique_chars)))\n",
    "            for c in zip(s,temp):\n",
    "                    c[1][mapping[c[0]]]=1\n",
    "            sequencias_procesadas.append(temp)\n",
    "        return sequencias_procesadas\n",
    "\n",
    "def wavelet(sequences, numeric=False, wavelet='db1', level=5):\n",
    "    templist=[]\n",
    "    if numeric==False:\n",
    "        for seq in sequences:\n",
    "            num_seq=[ord(char) for char in seq]\n",
    "            coeffs=pywt.wavedec(num_seq, wavelet, level)\n",
    "            templist.append(np.concatenate(coeffs))\n",
    "        return templist\n",
    "    elif numeric==True:\n",
    "        for seq in sequences:\n",
    "            coeffs=pywt.wavedec(seq, wavelet, level)\n",
    "            templist.append(np.concatenate(coeffs))\n",
    "        return templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d05c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sequence_id', 'aligned_sequence', 'original_sequence',\n",
       "       'sequence_length', 'domain', 'phylum', 'class', 'order', 'family',\n",
       "       'genus', 'species', 'is_training', 'padded_sequences', 'len_ps',\n",
       "       'len_as', 'clases_modelos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e234287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AS_One Hot']=one_hot(df['aligned_sequence'].values, len(df['aligned_sequence'][0]))\n",
    "\n",
    "df['AS_K-mers']=k_mers(df['aligned_sequence'].values)\n",
    "\n",
    "df['AS_FFT']=fourier(df['aligned_sequence'].values)\n",
    "\n",
    "df['AS_Wavelet']=wavelet(df['aligned_sequence'].values)\n",
    "\n",
    "df['AS_K-mers + FFT']=fourier(df['AS_K-mers'].values, False)\n",
    "df['AS_One Hot + FFT']=fourier(df['AS_One Hot'].values, False)\n",
    "\n",
    "df['AS_K-mers + Wavelet']=wavelet(df['AS_K-mers'].values, True)\n",
    "df['AS_One Hot + Wavelet']=wavelet(df['AS_One Hot'].values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b6c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PS_One Hot']=one_hot(df['padded_sequences'].values, len(df['padded_sequences'][0]))\n",
    "\n",
    "df['PS_K-mers']=k_mers(df['padded_sequences'].values)\n",
    "\n",
    "df['PS_FFT']=fourier(df['padded_sequences'].values)\n",
    "\n",
    "df['PS_Wavelet']=wavelet(df['padded_sequences'].values)\n",
    "\n",
    "df['PS_K-mers + FFT']=fourier(df['PS_K-mers'].values, False)\n",
    "df['PS_One Hot + FFT']=fourier(df['PS_One Hot'].values, False)\n",
    "\n",
    "df['PS_K-mers + Wavelet']=wavelet(df['PS_K-mers'].values, True)\n",
    "df['PS_One Hot + Wavelet']=wavelet(df['PS_One Hot'].values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63181595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_parquet('datos/encoded_data.parquet', index=False)\n",
    "# df.to_csv('datos/encoded_data.csv', index=False, sep='^')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
